{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "turbofan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWcMxjIzXsWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBQtEyIjXsWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train_FD001.txt', sep = ' ', header = None)\n",
        "df = df.drop(columns=[26, 27])\n",
        "df.columns = ([\"n_engine\",\"cycle\",\"opset_1\",\"opset_2\",\"opset_3\",\n",
        "              \"sens_1\",\"sens_2\",\"sens_3\",\"sens_4\",\"sens_5\",\"sens_6\",\"sens_7\",\"sens_8\",\"sens_9\",\"sens_10\",\n",
        "              \"sens_11\",\"sens_12\",\"sens_13\",\"sens_14\",\"sens_15\",\"sens_16\",\"sens_17\",\"sens_18\",\"sens_19\",\"sens_20\",\"sens_21\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9itZnX9hXsWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['sens_1','sens_5','sens_6','sens_10','sens_16','sens_18','sens_19'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu1lGYaaXsWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Agregada variable RUL\n",
        "\n",
        "RUL_temp=np.zeros(0)\n",
        "for i in range(1,df['n_engine'].max() + 1):\n",
        "    minus = np.linspace(1,df[df['n_engine']==i]['cycle'].max(),df[df['n_engine']==i]['cycle'].max())\n",
        "    RUL_engine = np.ones((df[df['n_engine']==i]['cycle'].max()))*df[df['n_engine']==i]['cycle'].max()\n",
        "    RUL_temp = np.append(RUL_temp,RUL_engine-minus)\n",
        "df['RUL'] = RUL_temp\n",
        "df['RUL'] = df['RUL'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYN_qflVXsWs",
        "colab_type": "code",
        "outputId": "6f4cb819-f749-409f-dfc0-08968e0a670c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_engine</th>\n",
              "      <th>cycle</th>\n",
              "      <th>opset_1</th>\n",
              "      <th>opset_2</th>\n",
              "      <th>opset_3</th>\n",
              "      <th>sens_2</th>\n",
              "      <th>sens_3</th>\n",
              "      <th>sens_4</th>\n",
              "      <th>sens_7</th>\n",
              "      <th>sens_8</th>\n",
              "      <th>sens_9</th>\n",
              "      <th>sens_11</th>\n",
              "      <th>sens_12</th>\n",
              "      <th>sens_13</th>\n",
              "      <th>sens_14</th>\n",
              "      <th>sens_15</th>\n",
              "      <th>sens_17</th>\n",
              "      <th>sens_20</th>\n",
              "      <th>sens_21</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.0007</td>\n",
              "      <td>-0.0004</td>\n",
              "      <td>100.0</td>\n",
              "      <td>641.82</td>\n",
              "      <td>1589.70</td>\n",
              "      <td>1400.60</td>\n",
              "      <td>554.36</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9046.19</td>\n",
              "      <td>47.47</td>\n",
              "      <td>521.66</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>8138.62</td>\n",
              "      <td>8.4195</td>\n",
              "      <td>392</td>\n",
              "      <td>39.06</td>\n",
              "      <td>23.4190</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0019</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.15</td>\n",
              "      <td>1591.82</td>\n",
              "      <td>1403.14</td>\n",
              "      <td>553.75</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9044.07</td>\n",
              "      <td>47.49</td>\n",
              "      <td>522.28</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>8131.49</td>\n",
              "      <td>8.4318</td>\n",
              "      <td>392</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.4236</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.0043</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1587.99</td>\n",
              "      <td>1404.20</td>\n",
              "      <td>554.26</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>9052.94</td>\n",
              "      <td>47.27</td>\n",
              "      <td>522.42</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8133.23</td>\n",
              "      <td>8.4178</td>\n",
              "      <td>390</td>\n",
              "      <td>38.95</td>\n",
              "      <td>23.3442</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0007</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.35</td>\n",
              "      <td>1582.79</td>\n",
              "      <td>1401.87</td>\n",
              "      <td>554.45</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9049.48</td>\n",
              "      <td>47.13</td>\n",
              "      <td>522.86</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8133.83</td>\n",
              "      <td>8.3682</td>\n",
              "      <td>392</td>\n",
              "      <td>38.88</td>\n",
              "      <td>23.3739</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.0019</td>\n",
              "      <td>-0.0002</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.37</td>\n",
              "      <td>1582.85</td>\n",
              "      <td>1406.22</td>\n",
              "      <td>554.00</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9055.15</td>\n",
              "      <td>47.28</td>\n",
              "      <td>522.19</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8133.80</td>\n",
              "      <td>8.4294</td>\n",
              "      <td>393</td>\n",
              "      <td>38.90</td>\n",
              "      <td>23.4044</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   n_engine  cycle  opset_1  opset_2  ...  sens_17  sens_20  sens_21  RUL\n",
              "0         1      1  -0.0007  -0.0004  ...      392    39.06  23.4190  191\n",
              "1         1      2   0.0019  -0.0003  ...      392    39.00  23.4236  190\n",
              "2         1      3  -0.0043   0.0003  ...      390    38.95  23.3442  189\n",
              "3         1      4   0.0007   0.0000  ...      392    38.88  23.3739  188\n",
              "4         1      5  -0.0019  -0.0002  ...      393    38.90  23.4044  187\n",
              "\n",
              "[5 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqmN__iOXsWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_maps=np.empty((15,14,1))\n",
        "df_ys = np.zeros((1,1))\n",
        "for i in range(1,df['n_engine'].max()+1):\n",
        "  #se obtienen los dataset de engines independientes en df_temp\n",
        "  df_temp1 = df[df['n_engine'] == i]\n",
        "  df_temp2 = df_temp1.drop(['n_engine','cycle','opset_1','opset_2','opset_3'],axis=1)\n",
        "  df_features = df_temp2.drop(['RUL'],axis = 1)\n",
        "  df_y = df_temp2['RUL'].to_numpy()\n",
        "  df_ys = np.append(df_ys,df_y[14:])\n",
        "  scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "  #minmaxsclaler aplicado entre (-1,1)\n",
        "  df_features = scaler.fit_transform(df_features)\n",
        "  #minmaxscaler\n",
        "  for j in range(len(df_y)-14):\n",
        "    feature_map = df_features[i:i+15][:]\n",
        "    features_maps = np.dstack((features_maps, feature_map))\n",
        "features_maps=np.delete(features_maps, 0, 2)\n",
        "df_ys = np.delete(df_ys, 0, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwW_ULNgXsW2",
        "colab_type": "code",
        "outputId": "ef8b2136-dc79-40dc-8047-1ac0c1bf4f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#como acceder a un feature map\n",
        "print(features_maps.shape)\n",
        "print(feature_map.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 14, 19231)\n",
            "(15, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnXLmy3taBHo",
        "colab_type": "code",
        "outputId": "22eed4ec-0408-4443-81c1-16b09c80903a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(df_ys.shape)\n",
        "print(df_y.shape)\n",
        "features_maps = np.moveaxis(features_maps, 2, 0)\n",
        "print(features_maps.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19231,)\n",
            "(200,)\n",
            "(19231, 15, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL4RKvXPl7cr",
        "colab_type": "code",
        "outputId": "2e504e3e-f4a5-4b7f-a237-38bba83bd921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df_ys = np.expand_dims(df_ys,axis=1)\n",
        "features_maps= np.expand_dims(features_maps,3)\n",
        "print(df_ys.shape)\n",
        "print(features_maps.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19231, 1)\n",
            "(19231, 15, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34B0T27buS5J",
        "colab_type": "text"
      },
      "source": [
        "# CNN \n",
        "\n",
        "Propuesta de Li, Ding, Sun\n",
        "\n",
        "![Imagen](https://github.com/farayal/memoria_turbofan/blob/master/cnn_regression.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxtZOMIu2y7",
        "colab_type": "code",
        "outputId": "a9f465a1-8d27-4fee-ae0a-13f097cdfb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fc-VMlVNKso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnnturbofan(input_shape):\n",
        "   \n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    #Layer 1\n",
        "    # Zero-Padding: Para originar un output (15,17) en la siguiente capa\n",
        "    X = ZeroPadding2D((7, 0))(X_input)\n",
        "\n",
        "    # CONV -> TANH aplicado a X\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1), name = 'conv0')(X_input)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 2\n",
        "    X = ZeroPadding2D((7, 0))(X_input)\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1), name = 'conv1')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 3\n",
        "    X = ZeroPadding2D((7, 0))(X_input)\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1), name = 'conv2')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 4\n",
        "    X = ZeroPadding2D((7, 0))(X_input)\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1), name = 'conv3')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 5\n",
        "    X = ZeroPadding2D((2, 0))(X_input)\n",
        "    X = Conv2D(1, (3, 1), strides = (1, 1), name = 'conv4')(X)\n",
        "    X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    # FLATTEN X (\"desenrollamos el feature map anterior\") + FULLYCONNECTED\n",
        "    X = Flatten()(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    X = Dense(100, activation='tanh', name='fully-connected')(X)\n",
        "    X = Dense(1,activation='linear',name = 'rul-neuron')(X)\n",
        "\n",
        "    # instancia modelo final\n",
        "    model = Model(inputs = X_input, outputs = X, name='cnnturbofan')\n",
        "    \n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yRAWMhx1KoC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "edb89775-69d3-4c1e-cc23-cb9850a1cbf6"
      },
      "source": [
        "cnnturbofan = cnnturbofan((features_maps.shape[1],features_maps.shape[2],features_maps.shape[3]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41z22sWe2W6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3b1cc1aa-166f-482d-b6c6-117416978ae0"
      },
      "source": [
        "cnnturbofan.compile(optimizer = \"Adam\", loss = \"mean_squared_error\", metrics = [\"mse\",\"accuracy\"])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgEw6sw31M0",
        "colab_type": "code",
        "outputId": "08fcf102-0662-4f41-cc06-8a7b33fbd077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "cnnturbofan.fit(x = features_maps, y = df_ys , epochs = 250, batch_size = 512)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Epoch 1/250\n",
            "19231/19231 [==============================] - 4s 190us/step - loss: 12768.6811 - mean_squared_error: 12768.6811 - acc: 0.0057\n",
            "Epoch 2/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 11323.5347 - mean_squared_error: 11323.5347 - acc: 0.0046\n",
            "Epoch 3/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 10614.6627 - mean_squared_error: 10614.6627 - acc: 0.0049\n",
            "Epoch 4/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 9998.0397 - mean_squared_error: 9998.0397 - acc: 0.0044\n",
            "Epoch 5/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 9439.1918 - mean_squared_error: 9439.1918 - acc: 0.0064\n",
            "Epoch 6/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 8928.8135 - mean_squared_error: 8928.8135 - acc: 0.0047\n",
            "Epoch 7/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 8462.8822 - mean_squared_error: 8462.8822 - acc: 0.0048\n",
            "Epoch 8/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 8035.0596 - mean_squared_error: 8035.0596 - acc: 0.0054\n",
            "Epoch 9/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 7643.8805 - mean_squared_error: 7643.8805 - acc: 0.0050\n",
            "Epoch 10/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 7285.5424 - mean_squared_error: 7285.5424 - acc: 0.0046\n",
            "Epoch 11/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 6959.3158 - mean_squared_error: 6959.3158 - acc: 0.0050\n",
            "Epoch 12/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 6661.1499 - mean_squared_error: 6661.1499 - acc: 0.0054\n",
            "Epoch 13/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 6390.0935 - mean_squared_error: 6390.0935 - acc: 0.0053\n",
            "Epoch 14/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 6144.9760 - mean_squared_error: 6144.9760 - acc: 0.0051\n",
            "Epoch 15/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 5923.5684 - mean_squared_error: 5923.5684 - acc: 0.0054\n",
            "Epoch 16/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 5723.0652 - mean_squared_error: 5723.0652 - acc: 0.0049\n",
            "Epoch 17/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 5544.0710 - mean_squared_error: 5544.0710 - acc: 0.0053\n",
            "Epoch 18/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 5382.3937 - mean_squared_error: 5382.3937 - acc: 0.0049\n",
            "Epoch 19/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 5238.4879 - mean_squared_error: 5238.4879 - acc: 0.0053\n",
            "Epoch 20/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 5110.2380 - mean_squared_error: 5110.2380 - acc: 0.0051\n",
            "Epoch 21/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4996.3103 - mean_squared_error: 4996.3103 - acc: 0.0054\n",
            "Epoch 22/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4895.1915 - mean_squared_error: 4895.1915 - acc: 0.0048\n",
            "Epoch 23/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 4806.3844 - mean_squared_error: 4806.3844 - acc: 0.0050\n",
            "Epoch 24/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4729.3711 - mean_squared_error: 4729.3711 - acc: 0.0048\n",
            "Epoch 25/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4660.4501 - mean_squared_error: 4660.4501 - acc: 0.0054\n",
            "Epoch 26/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4601.6701 - mean_squared_error: 4601.6701 - acc: 0.0058\n",
            "Epoch 27/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4549.4288 - mean_squared_error: 4549.4288 - acc: 0.0052\n",
            "Epoch 28/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4504.9996 - mean_squared_error: 4504.9996 - acc: 0.0045\n",
            "Epoch 29/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 4467.1160 - mean_squared_error: 4467.1160 - acc: 0.0049\n",
            "Epoch 30/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 4434.2351 - mean_squared_error: 4434.2351 - acc: 0.0047\n",
            "Epoch 31/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4406.1865 - mean_squared_error: 4406.1865 - acc: 0.0054\n",
            "Epoch 32/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4381.9166 - mean_squared_error: 4381.9166 - acc: 0.0050\n",
            "Epoch 33/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4360.6526 - mean_squared_error: 4360.6526 - acc: 0.0053\n",
            "Epoch 34/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 4341.5563 - mean_squared_error: 4341.5563 - acc: 0.0051\n",
            "Epoch 35/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 4323.5182 - mean_squared_error: 4323.5182 - acc: 0.0047\n",
            "Epoch 36/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4304.9524 - mean_squared_error: 4304.9524 - acc: 0.0055\n",
            "Epoch 37/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4284.3124 - mean_squared_error: 4284.3124 - acc: 0.0048\n",
            "Epoch 38/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4266.9886 - mean_squared_error: 4266.9886 - acc: 0.0051\n",
            "Epoch 39/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4246.8307 - mean_squared_error: 4246.8307 - acc: 0.0058\n",
            "Epoch 40/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4229.6897 - mean_squared_error: 4229.6897 - acc: 0.0047\n",
            "Epoch 41/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4211.0100 - mean_squared_error: 4211.0100 - acc: 0.0058\n",
            "Epoch 42/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4198.0594 - mean_squared_error: 4198.0594 - acc: 0.0053\n",
            "Epoch 43/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4179.8989 - mean_squared_error: 4179.8989 - acc: 0.0058\n",
            "Epoch 44/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4161.3148 - mean_squared_error: 4161.3148 - acc: 0.0049\n",
            "Epoch 45/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4138.9208 - mean_squared_error: 4138.9208 - acc: 0.0048\n",
            "Epoch 46/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 4117.5449 - mean_squared_error: 4117.5449 - acc: 0.0048\n",
            "Epoch 47/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4094.9670 - mean_squared_error: 4094.9670 - acc: 0.0048\n",
            "Epoch 48/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4082.1678 - mean_squared_error: 4082.1678 - acc: 0.0053\n",
            "Epoch 49/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4058.7856 - mean_squared_error: 4058.7856 - acc: 0.0053\n",
            "Epoch 50/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 4048.7981 - mean_squared_error: 4048.7981 - acc: 0.0059\n",
            "Epoch 51/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 4030.9581 - mean_squared_error: 4030.9581 - acc: 0.0045\n",
            "Epoch 52/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4015.7166 - mean_squared_error: 4015.7166 - acc: 0.0047\n",
            "Epoch 53/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 4002.6950 - mean_squared_error: 4002.6950 - acc: 0.0057\n",
            "Epoch 54/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3990.9340 - mean_squared_error: 3990.9340 - acc: 0.0051\n",
            "Epoch 55/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3973.3895 - mean_squared_error: 3973.3895 - acc: 0.0057\n",
            "Epoch 56/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3968.2841 - mean_squared_error: 3968.2841 - acc: 0.0046\n",
            "Epoch 57/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3955.6645 - mean_squared_error: 3955.6645 - acc: 0.0057\n",
            "Epoch 58/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3948.2084 - mean_squared_error: 3948.2084 - acc: 0.0058\n",
            "Epoch 59/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3937.6125 - mean_squared_error: 3937.6125 - acc: 0.0047\n",
            "Epoch 60/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3926.8011 - mean_squared_error: 3926.8011 - acc: 0.0049\n",
            "Epoch 61/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3919.2843 - mean_squared_error: 3919.2843 - acc: 0.0046\n",
            "Epoch 62/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3913.7892 - mean_squared_error: 3913.7892 - acc: 0.0058\n",
            "Epoch 63/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3906.9008 - mean_squared_error: 3906.9008 - acc: 0.0051\n",
            "Epoch 64/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3895.0965 - mean_squared_error: 3895.0965 - acc: 0.0049\n",
            "Epoch 65/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3889.9121 - mean_squared_error: 3889.9121 - acc: 0.0054\n",
            "Epoch 66/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3885.7235 - mean_squared_error: 3885.7235 - acc: 0.0058\n",
            "Epoch 67/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3869.0323 - mean_squared_error: 3869.0323 - acc: 0.0053\n",
            "Epoch 68/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3868.9417 - mean_squared_error: 3868.9417 - acc: 0.0052\n",
            "Epoch 69/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3863.0447 - mean_squared_error: 3863.0447 - acc: 0.0049\n",
            "Epoch 70/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3855.3801 - mean_squared_error: 3855.3801 - acc: 0.0055\n",
            "Epoch 71/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3855.4636 - mean_squared_error: 3855.4636 - acc: 0.0056\n",
            "Epoch 72/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3837.9035 - mean_squared_error: 3837.9035 - acc: 0.0043\n",
            "Epoch 73/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3843.3542 - mean_squared_error: 3843.3542 - acc: 0.0051\n",
            "Epoch 74/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3844.8932 - mean_squared_error: 3844.8932 - acc: 0.0050\n",
            "Epoch 75/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3838.7950 - mean_squared_error: 3838.7950 - acc: 0.0058\n",
            "Epoch 76/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3835.5090 - mean_squared_error: 3835.5090 - acc: 0.0053\n",
            "Epoch 77/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3826.4362 - mean_squared_error: 3826.4362 - acc: 0.0053\n",
            "Epoch 78/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3818.7519 - mean_squared_error: 3818.7519 - acc: 0.0050\n",
            "Epoch 79/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3817.5325 - mean_squared_error: 3817.5325 - acc: 0.0049\n",
            "Epoch 80/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3813.6870 - mean_squared_error: 3813.6870 - acc: 0.0051\n",
            "Epoch 81/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3799.9552 - mean_squared_error: 3799.9552 - acc: 0.0048\n",
            "Epoch 82/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3810.5796 - mean_squared_error: 3810.5796 - acc: 0.0054\n",
            "Epoch 83/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3809.3025 - mean_squared_error: 3809.3025 - acc: 0.0046\n",
            "Epoch 84/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3804.3642 - mean_squared_error: 3804.3642 - acc: 0.0054\n",
            "Epoch 85/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3789.4985 - mean_squared_error: 3789.4985 - acc: 0.0051\n",
            "Epoch 86/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3794.1859 - mean_squared_error: 3794.1859 - acc: 0.0056\n",
            "Epoch 87/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3798.1275 - mean_squared_error: 3798.1275 - acc: 0.0053\n",
            "Epoch 88/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3785.7890 - mean_squared_error: 3785.7890 - acc: 0.0058\n",
            "Epoch 89/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3789.6464 - mean_squared_error: 3789.6464 - acc: 0.0048\n",
            "Epoch 90/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3787.1607 - mean_squared_error: 3787.1607 - acc: 0.0049\n",
            "Epoch 91/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3777.9777 - mean_squared_error: 3777.9777 - acc: 0.0056\n",
            "Epoch 92/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3778.5326 - mean_squared_error: 3778.5326 - acc: 0.0049\n",
            "Epoch 93/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3786.3344 - mean_squared_error: 3786.3344 - acc: 0.0055\n",
            "Epoch 94/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3768.8477 - mean_squared_error: 3768.8477 - acc: 0.0056\n",
            "Epoch 95/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3775.0205 - mean_squared_error: 3775.0205 - acc: 0.0055\n",
            "Epoch 96/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3765.5716 - mean_squared_error: 3765.5716 - acc: 0.0047\n",
            "Epoch 97/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3774.0115 - mean_squared_error: 3774.0115 - acc: 0.0059\n",
            "Epoch 98/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3775.6550 - mean_squared_error: 3775.6550 - acc: 0.0055\n",
            "Epoch 99/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3769.9131 - mean_squared_error: 3769.9131 - acc: 0.0052\n",
            "Epoch 100/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3760.6766 - mean_squared_error: 3760.6766 - acc: 0.0055\n",
            "Epoch 101/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3759.0034 - mean_squared_error: 3759.0034 - acc: 0.0041\n",
            "Epoch 102/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3757.1039 - mean_squared_error: 3757.1039 - acc: 0.0046\n",
            "Epoch 103/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3758.0188 - mean_squared_error: 3758.0188 - acc: 0.0049\n",
            "Epoch 104/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3760.6519 - mean_squared_error: 3760.6519 - acc: 0.0049\n",
            "Epoch 105/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3752.8664 - mean_squared_error: 3752.8664 - acc: 0.0045\n",
            "Epoch 106/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3763.5634 - mean_squared_error: 3763.5634 - acc: 0.0051\n",
            "Epoch 107/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3747.3267 - mean_squared_error: 3747.3267 - acc: 0.0054\n",
            "Epoch 108/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3747.1875 - mean_squared_error: 3747.1875 - acc: 0.0044\n",
            "Epoch 109/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3748.2078 - mean_squared_error: 3748.2078 - acc: 0.0054\n",
            "Epoch 110/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3759.1430 - mean_squared_error: 3759.1430 - acc: 0.0051\n",
            "Epoch 111/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3750.7588 - mean_squared_error: 3750.7588 - acc: 0.0051\n",
            "Epoch 112/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3746.7976 - mean_squared_error: 3746.7976 - acc: 0.0052\n",
            "Epoch 113/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3740.6183 - mean_squared_error: 3740.6183 - acc: 0.0054\n",
            "Epoch 114/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3742.3010 - mean_squared_error: 3742.3010 - acc: 0.0059\n",
            "Epoch 115/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3745.8889 - mean_squared_error: 3745.8889 - acc: 0.0054\n",
            "Epoch 116/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3744.5550 - mean_squared_error: 3744.5550 - acc: 0.0063\n",
            "Epoch 117/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3742.7538 - mean_squared_error: 3742.7538 - acc: 0.0045\n",
            "Epoch 118/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3743.6277 - mean_squared_error: 3743.6277 - acc: 0.0056\n",
            "Epoch 119/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3739.9915 - mean_squared_error: 3739.9915 - acc: 0.0052\n",
            "Epoch 120/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3745.5849 - mean_squared_error: 3745.5849 - acc: 0.0050\n",
            "Epoch 121/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3738.9102 - mean_squared_error: 3738.9102 - acc: 0.0054\n",
            "Epoch 122/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3729.5469 - mean_squared_error: 3729.5469 - acc: 0.0050\n",
            "Epoch 123/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3726.7874 - mean_squared_error: 3726.7874 - acc: 0.0049\n",
            "Epoch 124/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3734.3361 - mean_squared_error: 3734.3361 - acc: 0.0060\n",
            "Epoch 125/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3738.4578 - mean_squared_error: 3738.4578 - acc: 0.0063\n",
            "Epoch 126/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3735.4809 - mean_squared_error: 3735.4809 - acc: 0.0046\n",
            "Epoch 127/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3741.6553 - mean_squared_error: 3741.6553 - acc: 0.0050\n",
            "Epoch 128/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3727.2151 - mean_squared_error: 3727.2151 - acc: 0.0049\n",
            "Epoch 129/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3733.1775 - mean_squared_error: 3733.1775 - acc: 0.0059\n",
            "Epoch 130/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3723.7982 - mean_squared_error: 3723.7982 - acc: 0.0055\n",
            "Epoch 131/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3740.2294 - mean_squared_error: 3740.2294 - acc: 0.0050\n",
            "Epoch 132/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3723.8714 - mean_squared_error: 3723.8714 - acc: 0.0056\n",
            "Epoch 133/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3736.8619 - mean_squared_error: 3736.8619 - acc: 0.0062\n",
            "Epoch 134/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3730.9572 - mean_squared_error: 3730.9572 - acc: 0.0053\n",
            "Epoch 135/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3720.5499 - mean_squared_error: 3720.5499 - acc: 0.0053\n",
            "Epoch 136/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3718.1227 - mean_squared_error: 3718.1227 - acc: 0.0047\n",
            "Epoch 137/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3733.1059 - mean_squared_error: 3733.1059 - acc: 0.0058\n",
            "Epoch 138/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3728.1042 - mean_squared_error: 3728.1042 - acc: 0.0052\n",
            "Epoch 139/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3721.1527 - mean_squared_error: 3721.1527 - acc: 0.0056\n",
            "Epoch 140/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3726.0513 - mean_squared_error: 3726.0513 - acc: 0.0053\n",
            "Epoch 141/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3720.5796 - mean_squared_error: 3720.5796 - acc: 0.0047\n",
            "Epoch 142/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3715.8162 - mean_squared_error: 3715.8162 - acc: 0.0049\n",
            "Epoch 143/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3705.8499 - mean_squared_error: 3705.8499 - acc: 0.0058\n",
            "Epoch 144/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3719.3269 - mean_squared_error: 3719.3269 - acc: 0.0040\n",
            "Epoch 145/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3720.9575 - mean_squared_error: 3720.9575 - acc: 0.0054\n",
            "Epoch 146/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3711.2162 - mean_squared_error: 3711.2162 - acc: 0.0052\n",
            "Epoch 147/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3710.8748 - mean_squared_error: 3710.8748 - acc: 0.0049\n",
            "Epoch 148/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3710.7827 - mean_squared_error: 3710.7827 - acc: 0.0047\n",
            "Epoch 149/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3731.1173 - mean_squared_error: 3731.1173 - acc: 0.0048\n",
            "Epoch 150/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3714.7533 - mean_squared_error: 3714.7533 - acc: 0.0052\n",
            "Epoch 151/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3716.7727 - mean_squared_error: 3716.7727 - acc: 0.0046\n",
            "Epoch 152/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3712.3091 - mean_squared_error: 3712.3091 - acc: 0.0054\n",
            "Epoch 153/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3719.6911 - mean_squared_error: 3719.6911 - acc: 0.0054\n",
            "Epoch 154/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3711.2634 - mean_squared_error: 3711.2634 - acc: 0.0046\n",
            "Epoch 155/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3711.3357 - mean_squared_error: 3711.3357 - acc: 0.0065\n",
            "Epoch 156/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3711.8571 - mean_squared_error: 3711.8571 - acc: 0.0055\n",
            "Epoch 157/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3699.0513 - mean_squared_error: 3699.0513 - acc: 0.0056\n",
            "Epoch 158/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3709.4752 - mean_squared_error: 3709.4752 - acc: 0.0038\n",
            "Epoch 159/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3714.6045 - mean_squared_error: 3714.6045 - acc: 0.0058\n",
            "Epoch 160/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3716.5908 - mean_squared_error: 3716.5908 - acc: 0.0061\n",
            "Epoch 161/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3709.7259 - mean_squared_error: 3709.7259 - acc: 0.0052\n",
            "Epoch 162/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3717.5607 - mean_squared_error: 3717.5607 - acc: 0.0061\n",
            "Epoch 163/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3704.9923 - mean_squared_error: 3704.9923 - acc: 0.0055\n",
            "Epoch 164/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3708.6219 - mean_squared_error: 3708.6219 - acc: 0.0059\n",
            "Epoch 165/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3699.9771 - mean_squared_error: 3699.9771 - acc: 0.0060\n",
            "Epoch 166/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3704.6818 - mean_squared_error: 3704.6818 - acc: 0.0047\n",
            "Epoch 167/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3715.5111 - mean_squared_error: 3715.5111 - acc: 0.0050\n",
            "Epoch 168/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3709.6762 - mean_squared_error: 3709.6762 - acc: 0.0053\n",
            "Epoch 169/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3702.2482 - mean_squared_error: 3702.2482 - acc: 0.0051\n",
            "Epoch 170/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3701.9484 - mean_squared_error: 3701.9484 - acc: 0.0048\n",
            "Epoch 171/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3701.3270 - mean_squared_error: 3701.3270 - acc: 0.0045\n",
            "Epoch 172/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3708.2429 - mean_squared_error: 3708.2429 - acc: 0.0046\n",
            "Epoch 173/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3706.7331 - mean_squared_error: 3706.7331 - acc: 0.0059\n",
            "Epoch 174/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3697.8889 - mean_squared_error: 3697.8889 - acc: 0.0055\n",
            "Epoch 175/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3699.5687 - mean_squared_error: 3699.5687 - acc: 0.0050\n",
            "Epoch 176/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3709.9009 - mean_squared_error: 3709.9009 - acc: 0.0057\n",
            "Epoch 177/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3697.7676 - mean_squared_error: 3697.7676 - acc: 0.0045\n",
            "Epoch 178/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3706.1369 - mean_squared_error: 3706.1369 - acc: 0.0055\n",
            "Epoch 179/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3702.0812 - mean_squared_error: 3702.0812 - acc: 0.0047\n",
            "Epoch 180/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3711.8596 - mean_squared_error: 3711.8596 - acc: 0.0058\n",
            "Epoch 181/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3708.7932 - mean_squared_error: 3708.7932 - acc: 0.0050\n",
            "Epoch 182/250\n",
            "19231/19231 [==============================] - 0s 19us/step - loss: 3702.6441 - mean_squared_error: 3702.6441 - acc: 0.0054\n",
            "Epoch 183/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3690.7586 - mean_squared_error: 3690.7586 - acc: 0.0049\n",
            "Epoch 184/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3706.3574 - mean_squared_error: 3706.3574 - acc: 0.0063\n",
            "Epoch 185/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3702.3917 - mean_squared_error: 3702.3917 - acc: 0.0047\n",
            "Epoch 186/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3696.1862 - mean_squared_error: 3696.1862 - acc: 0.0052\n",
            "Epoch 187/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3703.8303 - mean_squared_error: 3703.8303 - acc: 0.0056\n",
            "Epoch 188/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3710.3392 - mean_squared_error: 3710.3392 - acc: 0.0044\n",
            "Epoch 189/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3700.3823 - mean_squared_error: 3700.3823 - acc: 0.0057\n",
            "Epoch 190/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3701.3868 - mean_squared_error: 3701.3868 - acc: 0.0053\n",
            "Epoch 191/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3710.4740 - mean_squared_error: 3710.4740 - acc: 0.0044\n",
            "Epoch 192/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3688.0522 - mean_squared_error: 3688.0522 - acc: 0.0049\n",
            "Epoch 193/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3699.7890 - mean_squared_error: 3699.7890 - acc: 0.0052\n",
            "Epoch 194/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3701.0485 - mean_squared_error: 3701.0485 - acc: 0.0051\n",
            "Epoch 195/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3699.6791 - mean_squared_error: 3699.6791 - acc: 0.0062\n",
            "Epoch 196/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3690.1250 - mean_squared_error: 3690.1250 - acc: 0.0050\n",
            "Epoch 197/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3696.5719 - mean_squared_error: 3696.5719 - acc: 0.0047\n",
            "Epoch 198/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3682.1021 - mean_squared_error: 3682.1021 - acc: 0.0047\n",
            "Epoch 199/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3708.9518 - mean_squared_error: 3708.9518 - acc: 0.0050\n",
            "Epoch 200/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3697.8855 - mean_squared_error: 3697.8855 - acc: 0.0047\n",
            "Epoch 201/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3697.8601 - mean_squared_error: 3697.8601 - acc: 0.0061\n",
            "Epoch 202/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3698.4328 - mean_squared_error: 3698.4328 - acc: 0.0047\n",
            "Epoch 203/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3697.7808 - mean_squared_error: 3697.7808 - acc: 0.0057\n",
            "Epoch 204/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3704.2421 - mean_squared_error: 3704.2421 - acc: 0.0046\n",
            "Epoch 205/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3693.9495 - mean_squared_error: 3693.9495 - acc: 0.0060\n",
            "Epoch 206/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3691.6684 - mean_squared_error: 3691.6684 - acc: 0.0055\n",
            "Epoch 207/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3704.2114 - mean_squared_error: 3704.2114 - acc: 0.0050\n",
            "Epoch 208/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3696.0478 - mean_squared_error: 3696.0478 - acc: 0.0048\n",
            "Epoch 209/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3696.8828 - mean_squared_error: 3696.8828 - acc: 0.0053\n",
            "Epoch 210/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3705.9225 - mean_squared_error: 3705.9225 - acc: 0.0055\n",
            "Epoch 211/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3691.9377 - mean_squared_error: 3691.9377 - acc: 0.0048\n",
            "Epoch 212/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3688.7973 - mean_squared_error: 3688.7973 - acc: 0.0058\n",
            "Epoch 213/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3690.6501 - mean_squared_error: 3690.6501 - acc: 0.0049\n",
            "Epoch 214/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3692.5285 - mean_squared_error: 3692.5285 - acc: 0.0046\n",
            "Epoch 215/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3698.8829 - mean_squared_error: 3698.8829 - acc: 0.0053\n",
            "Epoch 216/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3690.6609 - mean_squared_error: 3690.6609 - acc: 0.0055\n",
            "Epoch 217/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3699.4344 - mean_squared_error: 3699.4344 - acc: 0.0051\n",
            "Epoch 218/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3696.0219 - mean_squared_error: 3696.0219 - acc: 0.0051\n",
            "Epoch 219/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3694.6049 - mean_squared_error: 3694.6049 - acc: 0.0050\n",
            "Epoch 220/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3694.8498 - mean_squared_error: 3694.8498 - acc: 0.0047\n",
            "Epoch 221/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3699.3253 - mean_squared_error: 3699.3253 - acc: 0.0053\n",
            "Epoch 222/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3688.6451 - mean_squared_error: 3688.6451 - acc: 0.0050\n",
            "Epoch 223/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3698.2325 - mean_squared_error: 3698.2325 - acc: 0.0054\n",
            "Epoch 224/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3688.6644 - mean_squared_error: 3688.6644 - acc: 0.0054\n",
            "Epoch 225/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3697.0068 - mean_squared_error: 3697.0068 - acc: 0.0047\n",
            "Epoch 226/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3699.4798 - mean_squared_error: 3699.4798 - acc: 0.0052\n",
            "Epoch 227/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3695.0281 - mean_squared_error: 3695.0281 - acc: 0.0057\n",
            "Epoch 228/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3686.7150 - mean_squared_error: 3686.7150 - acc: 0.0051\n",
            "Epoch 229/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3679.3192 - mean_squared_error: 3679.3192 - acc: 0.0053\n",
            "Epoch 230/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3688.8010 - mean_squared_error: 3688.8010 - acc: 0.0047\n",
            "Epoch 231/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3701.9719 - mean_squared_error: 3701.9719 - acc: 0.0051\n",
            "Epoch 232/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3689.9139 - mean_squared_error: 3689.9139 - acc: 0.0047\n",
            "Epoch 233/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3698.1181 - mean_squared_error: 3698.1181 - acc: 0.0048\n",
            "Epoch 234/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3692.8235 - mean_squared_error: 3692.8235 - acc: 0.0057\n",
            "Epoch 235/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3688.8094 - mean_squared_error: 3688.8094 - acc: 0.0045\n",
            "Epoch 236/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3692.9166 - mean_squared_error: 3692.9166 - acc: 0.0054\n",
            "Epoch 237/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3688.4737 - mean_squared_error: 3688.4737 - acc: 0.0047\n",
            "Epoch 238/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3695.4796 - mean_squared_error: 3695.4796 - acc: 0.0047\n",
            "Epoch 239/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3682.1569 - mean_squared_error: 3682.1569 - acc: 0.0051\n",
            "Epoch 240/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3691.5408 - mean_squared_error: 3691.5408 - acc: 0.0047\n",
            "Epoch 241/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3682.1461 - mean_squared_error: 3682.1461 - acc: 0.0051\n",
            "Epoch 242/250\n",
            "19231/19231 [==============================] - 0s 18us/step - loss: 3691.7024 - mean_squared_error: 3691.7024 - acc: 0.0049\n",
            "Epoch 243/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3699.1399 - mean_squared_error: 3699.1399 - acc: 0.0051\n",
            "Epoch 244/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3695.8697 - mean_squared_error: 3695.8697 - acc: 0.0050\n",
            "Epoch 245/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3696.5277 - mean_squared_error: 3696.5277 - acc: 0.0054\n",
            "Epoch 246/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3691.2089 - mean_squared_error: 3691.2089 - acc: 0.0064\n",
            "Epoch 247/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3691.0258 - mean_squared_error: 3691.0258 - acc: 0.0054\n",
            "Epoch 248/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3683.7536 - mean_squared_error: 3683.7536 - acc: 0.0051\n",
            "Epoch 249/250\n",
            "19231/19231 [==============================] - 0s 16us/step - loss: 3693.1795 - mean_squared_error: 3693.1795 - acc: 0.0049\n",
            "Epoch 250/250\n",
            "19231/19231 [==============================] - 0s 17us/step - loss: 3684.7329 - mean_squared_error: 3684.7329 - acc: 0.0049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff116175fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H_S6LK541Gs",
        "colab_type": "code",
        "outputId": "1d710e6e-aa5a-4fdc-8538-fd6f54d52e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "cnnturbofan.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnnturbofan\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 15, 14, 1)         0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 19, 14, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 17, 14, 1)         4         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 17, 14, 1)         4         \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 17, 14, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 238)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 238)               0         \n",
            "_________________________________________________________________\n",
            "fully-connected (Dense)      (None, 100)               23900     \n",
            "_________________________________________________________________\n",
            "rul-neuron (Dense)           (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 24,009\n",
            "Trainable params: 24,007\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj2BQVWTHspb",
        "colab_type": "code",
        "outputId": "d03e056b-f807-43a4-8412-3fabb26145da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "cnnturbofan.predict(features_maps)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[88.91917],\n",
              "       [88.91917],\n",
              "       [88.91917],\n",
              "       ...,\n",
              "       [94.35182],\n",
              "       [94.35182],\n",
              "       [94.35182]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxPKSzTQlmek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}