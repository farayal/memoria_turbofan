{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "turbofan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWcMxjIzXsWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBQtEyIjXsWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('train_FD001.txt', sep = ' ', header = None)\n",
        "df = df.drop(columns=[26, 27])\n",
        "df.columns = ([\"n_engine\",\"cycle\",\"opset_1\",\"opset_2\",\"opset_3\",\n",
        "              \"sens_1\",\"sens_2\",\"sens_3\",\"sens_4\",\"sens_5\",\"sens_6\",\"sens_7\",\"sens_8\",\"sens_9\",\"sens_10\",\n",
        "              \"sens_11\",\"sens_12\",\"sens_13\",\"sens_14\",\"sens_15\",\"sens_16\",\"sens_17\",\"sens_18\",\"sens_19\",\"sens_20\",\"sens_21\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9itZnX9hXsWk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop(['sens_1','sens_5','sens_6','sens_10','sens_16','sens_18','sens_19'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu1lGYaaXsWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Agregada variable RUL\n",
        "RUL_temp=np.zeros(0)\n",
        "for i in range(1,df['n_engine'].max() + 1):\n",
        "    minus = np.linspace(1,df[df['n_engine']==i]['cycle'].max(),df[df['n_engine']==i]['cycle'].max())\n",
        "    RUL_engine = np.ones((df[df['n_engine']==i]['cycle'].max()))*df[df['n_engine']==i]['cycle'].max()\n",
        "    RUL_temp = np.append(RUL_temp,RUL_engine-minus)\n",
        "df['RUL'] = RUL_temp\n",
        "df['RUL'] = df['RUL'].astype(int)\n",
        "scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "df[df.columns[1:19]]= scaler.fit_transform(df[df.columns[1:19]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYN_qflVXsWs",
        "colab_type": "code",
        "outputId": "8f6a033c-b84e-4b45-c7f1-bbe68e7f0eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        }
      },
      "source": [
        "df.iloc[0:30][:]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_engine</th>\n",
              "      <th>cycle</th>\n",
              "      <th>opset_1</th>\n",
              "      <th>opset_2</th>\n",
              "      <th>opset_3</th>\n",
              "      <th>sens_2</th>\n",
              "      <th>sens_3</th>\n",
              "      <th>sens_4</th>\n",
              "      <th>sens_7</th>\n",
              "      <th>sens_8</th>\n",
              "      <th>sens_9</th>\n",
              "      <th>sens_11</th>\n",
              "      <th>sens_12</th>\n",
              "      <th>sens_13</th>\n",
              "      <th>sens_14</th>\n",
              "      <th>sens_15</th>\n",
              "      <th>sens_17</th>\n",
              "      <th>sens_20</th>\n",
              "      <th>sens_21</th>\n",
              "      <th>RUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-0.080460</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.632530</td>\n",
              "      <td>-0.186396</td>\n",
              "      <td>-0.380486</td>\n",
              "      <td>0.452496</td>\n",
              "      <td>-0.515152</td>\n",
              "      <td>-0.780490</td>\n",
              "      <td>-0.261905</td>\n",
              "      <td>0.266525</td>\n",
              "      <td>-0.588235</td>\n",
              "      <td>-0.600784</td>\n",
              "      <td>-0.272028</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.426357</td>\n",
              "      <td>0.449323</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.994460</td>\n",
              "      <td>0.218391</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.433735</td>\n",
              "      <td>-0.093961</td>\n",
              "      <td>-0.294733</td>\n",
              "      <td>0.256039</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>-0.799515</td>\n",
              "      <td>-0.238095</td>\n",
              "      <td>0.530917</td>\n",
              "      <td>-0.441176</td>\n",
              "      <td>-0.674373</td>\n",
              "      <td>-0.177376</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.462027</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.988920</td>\n",
              "      <td>-0.494253</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.313253</td>\n",
              "      <td>-0.260955</td>\n",
              "      <td>-0.258947</td>\n",
              "      <td>0.420290</td>\n",
              "      <td>-0.454545</td>\n",
              "      <td>-0.719914</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.590618</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.656414</td>\n",
              "      <td>-0.285110</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>0.242751</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.983380</td>\n",
              "      <td>0.080460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.313253</td>\n",
              "      <td>-0.487683</td>\n",
              "      <td>-0.337610</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>-0.363636</td>\n",
              "      <td>-0.750965</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.778252</td>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.650222</td>\n",
              "      <td>-0.666795</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.147287</td>\n",
              "      <td>0.324772</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.977839</td>\n",
              "      <td>-0.218391</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.301205</td>\n",
              "      <td>-0.485066</td>\n",
              "      <td>-0.190749</td>\n",
              "      <td>0.336554</td>\n",
              "      <td>-0.515152</td>\n",
              "      <td>-0.700081</td>\n",
              "      <td>-0.488095</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>-0.529412</td>\n",
              "      <td>-0.650532</td>\n",
              "      <td>-0.195845</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.178295</td>\n",
              "      <td>0.409003</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.972299</td>\n",
              "      <td>-0.494253</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.463855</td>\n",
              "      <td>-0.414432</td>\n",
              "      <td>-0.455773</td>\n",
              "      <td>0.552335</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.749170</td>\n",
              "      <td>-0.630952</td>\n",
              "      <td>0.275053</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.660336</td>\n",
              "      <td>-0.338977</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.302326</td>\n",
              "      <td>0.305440</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966759</td>\n",
              "      <td>0.114943</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.234940</td>\n",
              "      <td>-0.072160</td>\n",
              "      <td>-0.476030</td>\n",
              "      <td>0.446055</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.664363</td>\n",
              "      <td>-0.392857</td>\n",
              "      <td>0.547974</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.665807</td>\n",
              "      <td>-0.442093</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.488372</td>\n",
              "      <td>0.334438</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.961219</td>\n",
              "      <td>-0.390805</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.186747</td>\n",
              "      <td>-0.480270</td>\n",
              "      <td>-0.367995</td>\n",
              "      <td>0.288245</td>\n",
              "      <td>-0.696970</td>\n",
              "      <td>-0.828861</td>\n",
              "      <td>-0.535714</td>\n",
              "      <td>0.611940</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.678708</td>\n",
              "      <td>-0.363601</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.286822</td>\n",
              "      <td>0.149959</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.955679</td>\n",
              "      <td>0.091954</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.451807</td>\n",
              "      <td>-0.130586</td>\n",
              "      <td>-0.576300</td>\n",
              "      <td>0.236715</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.778067</td>\n",
              "      <td>-0.476190</td>\n",
              "      <td>0.321962</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.734235</td>\n",
              "      <td>-0.631397</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.410853</td>\n",
              "      <td>0.415079</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.950139</td>\n",
              "      <td>-0.379310</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.698795</td>\n",
              "      <td>-0.119250</td>\n",
              "      <td>-0.385213</td>\n",
              "      <td>0.204509</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.731042</td>\n",
              "      <td>-0.785714</td>\n",
              "      <td>0.321962</td>\n",
              "      <td>-0.470588</td>\n",
              "      <td>-0.696150</td>\n",
              "      <td>-0.202001</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>0.588511</td>\n",
              "      <td>182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.944598</td>\n",
              "      <td>0.206897</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.355422</td>\n",
              "      <td>-0.533028</td>\n",
              "      <td>-0.379136</td>\n",
              "      <td>0.510467</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.749798</td>\n",
              "      <td>-0.642857</td>\n",
              "      <td>0.155650</td>\n",
              "      <td>-0.617647</td>\n",
              "      <td>-0.580555</td>\n",
              "      <td>-0.160446</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.240310</td>\n",
              "      <td>0.614195</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.939058</td>\n",
              "      <td>0.183908</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.487952</td>\n",
              "      <td>-0.460650</td>\n",
              "      <td>-0.395679</td>\n",
              "      <td>0.504026</td>\n",
              "      <td>-0.424242</td>\n",
              "      <td>-0.751952</td>\n",
              "      <td>-0.607143</td>\n",
              "      <td>0.326226</td>\n",
              "      <td>-0.588235</td>\n",
              "      <td>-0.645887</td>\n",
              "      <td>-0.469796</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.426357</td>\n",
              "      <td>0.302955</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.933518</td>\n",
              "      <td>-0.218391</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.120482</td>\n",
              "      <td>-0.513843</td>\n",
              "      <td>-0.372721</td>\n",
              "      <td>0.156200</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.774836</td>\n",
              "      <td>-0.369048</td>\n",
              "      <td>0.347548</td>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.709361</td>\n",
              "      <td>-0.305117</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.224806</td>\n",
              "      <td>0.053576</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.927978</td>\n",
              "      <td>0.103448</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.313253</td>\n",
              "      <td>-0.044692</td>\n",
              "      <td>-0.429102</td>\n",
              "      <td>0.491143</td>\n",
              "      <td>-0.424242</td>\n",
              "      <td>-0.769900</td>\n",
              "      <td>-0.297619</td>\n",
              "      <td>0.270789</td>\n",
              "      <td>-0.647059</td>\n",
              "      <td>-0.644029</td>\n",
              "      <td>-0.449788</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.612403</td>\n",
              "      <td>0.348799</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.922438</td>\n",
              "      <td>-0.206897</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.265060</td>\n",
              "      <td>-0.442773</td>\n",
              "      <td>-0.328832</td>\n",
              "      <td>0.220612</td>\n",
              "      <td>-0.363636</td>\n",
              "      <td>-0.726375</td>\n",
              "      <td>-0.464286</td>\n",
              "      <td>0.624733</td>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.714934</td>\n",
              "      <td>-0.268950</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.317829</td>\n",
              "      <td>0.258768</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.916898</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.445783</td>\n",
              "      <td>-0.261391</td>\n",
              "      <td>-0.248818</td>\n",
              "      <td>0.317230</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.752221</td>\n",
              "      <td>-0.535714</td>\n",
              "      <td>0.194030</td>\n",
              "      <td>-0.441176</td>\n",
              "      <td>-0.626690</td>\n",
              "      <td>-0.471335</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.286822</td>\n",
              "      <td>0.548743</td>\n",
              "      <td>176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.911357</td>\n",
              "      <td>0.022989</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.174699</td>\n",
              "      <td>-0.393067</td>\n",
              "      <td>-0.402431</td>\n",
              "      <td>0.272142</td>\n",
              "      <td>-0.515152</td>\n",
              "      <td>-0.702145</td>\n",
              "      <td>-0.678571</td>\n",
              "      <td>0.364606</td>\n",
              "      <td>-0.529412</td>\n",
              "      <td>-0.614718</td>\n",
              "      <td>-0.005002</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.038760</td>\n",
              "      <td>0.208782</td>\n",
              "      <td>175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.905817</td>\n",
              "      <td>-0.356322</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.150602</td>\n",
              "      <td>-0.127970</td>\n",
              "      <td>-0.531735</td>\n",
              "      <td>0.400966</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.750337</td>\n",
              "      <td>-0.571429</td>\n",
              "      <td>0.309168</td>\n",
              "      <td>-0.441176</td>\n",
              "      <td>-0.661575</td>\n",
              "      <td>-0.400539</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>0.393262</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.900277</td>\n",
              "      <td>0.367816</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.650602</td>\n",
              "      <td>-0.279704</td>\n",
              "      <td>-0.388926</td>\n",
              "      <td>0.394525</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>-0.710491</td>\n",
              "      <td>-0.345238</td>\n",
              "      <td>0.364606</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.698731</td>\n",
              "      <td>-0.175067</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.023256</td>\n",
              "      <td>0.248826</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.894737</td>\n",
              "      <td>-0.425287</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.102410</td>\n",
              "      <td>-0.560933</td>\n",
              "      <td>-0.224173</td>\n",
              "      <td>0.597424</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.783093</td>\n",
              "      <td>-0.559524</td>\n",
              "      <td>0.441365</td>\n",
              "      <td>-0.588235</td>\n",
              "      <td>-0.692744</td>\n",
              "      <td>-0.260485</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.379845</td>\n",
              "      <td>0.457608</td>\n",
              "      <td>172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.889197</td>\n",
              "      <td>-0.137931</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.301205</td>\n",
              "      <td>-0.344670</td>\n",
              "      <td>-0.463876</td>\n",
              "      <td>0.362319</td>\n",
              "      <td>-0.363636</td>\n",
              "      <td>-0.762900</td>\n",
              "      <td>-0.642857</td>\n",
              "      <td>0.590618</td>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.648261</td>\n",
              "      <td>-0.384379</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.472868</td>\n",
              "      <td>0.148578</td>\n",
              "      <td>171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.883657</td>\n",
              "      <td>0.022989</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.060241</td>\n",
              "      <td>-0.045564</td>\n",
              "      <td>-0.381499</td>\n",
              "      <td>0.217391</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>-0.645697</td>\n",
              "      <td>-0.535714</td>\n",
              "      <td>0.411514</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.685520</td>\n",
              "      <td>-0.395922</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.209302</td>\n",
              "      <td>0.339409</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.878116</td>\n",
              "      <td>0.390805</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.439759</td>\n",
              "      <td>-0.252235</td>\n",
              "      <td>-0.577988</td>\n",
              "      <td>0.330113</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.779682</td>\n",
              "      <td>-0.523810</td>\n",
              "      <td>0.206823</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.711425</td>\n",
              "      <td>-0.237399</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.240310</td>\n",
              "      <td>0.552057</td>\n",
              "      <td>169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.872576</td>\n",
              "      <td>-0.114943</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.295181</td>\n",
              "      <td>-0.137127</td>\n",
              "      <td>-0.440918</td>\n",
              "      <td>0.172303</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.802297</td>\n",
              "      <td>-0.297619</td>\n",
              "      <td>0.466951</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.649706</td>\n",
              "      <td>-0.505964</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.312897</td>\n",
              "      <td>168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.867036</td>\n",
              "      <td>0.264368</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.060241</td>\n",
              "      <td>0.005450</td>\n",
              "      <td>-0.421337</td>\n",
              "      <td>0.336554</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.708965</td>\n",
              "      <td>-0.392857</td>\n",
              "      <td>0.650320</td>\n",
              "      <td>-0.588235</td>\n",
              "      <td>-0.621530</td>\n",
              "      <td>-0.485956</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.255814</td>\n",
              "      <td>0.476388</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.861496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.427711</td>\n",
              "      <td>-0.213429</td>\n",
              "      <td>-0.533423</td>\n",
              "      <td>0.371981</td>\n",
              "      <td>-0.484848</td>\n",
              "      <td>-0.772234</td>\n",
              "      <td>-0.511905</td>\n",
              "      <td>0.530917</td>\n",
              "      <td>-0.470588</td>\n",
              "      <td>-0.677882</td>\n",
              "      <td>-0.222008</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.438001</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.855956</td>\n",
              "      <td>-0.137931</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.259036</td>\n",
              "      <td>-0.152823</td>\n",
              "      <td>-0.338623</td>\n",
              "      <td>0.359098</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>-0.764606</td>\n",
              "      <td>-0.380952</td>\n",
              "      <td>0.411514</td>\n",
              "      <td>-0.264706</td>\n",
              "      <td>-0.642275</td>\n",
              "      <td>-0.386687</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.317829</td>\n",
              "      <td>0.527202</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.850416</td>\n",
              "      <td>-0.275862</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.313253</td>\n",
              "      <td>-0.485503</td>\n",
              "      <td>-0.430115</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.747734</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.654584</td>\n",
              "      <td>-0.411765</td>\n",
              "      <td>-0.717618</td>\n",
              "      <td>-0.173528</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.348837</td>\n",
              "      <td>0.076774</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.844875</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.578313</td>\n",
              "      <td>-0.398736</td>\n",
              "      <td>-0.367319</td>\n",
              "      <td>0.417069</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.742080</td>\n",
              "      <td>-0.535714</td>\n",
              "      <td>0.586354</td>\n",
              "      <td>-0.470588</td>\n",
              "      <td>-0.658169</td>\n",
              "      <td>-0.276645</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.224806</td>\n",
              "      <td>0.285556</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.839335</td>\n",
              "      <td>-0.252874</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.403614</td>\n",
              "      <td>-0.019839</td>\n",
              "      <td>-0.533086</td>\n",
              "      <td>0.455717</td>\n",
              "      <td>-0.484848</td>\n",
              "      <td>-0.785605</td>\n",
              "      <td>-0.345238</td>\n",
              "      <td>0.492537</td>\n",
              "      <td>-0.647059</td>\n",
              "      <td>-0.608628</td>\n",
              "      <td>-0.372066</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.410853</td>\n",
              "      <td>0.427230</td>\n",
              "      <td>162</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    n_engine     cycle   opset_1   opset_2  ...   sens_17   sens_20   sens_21  RUL\n",
              "0          1 -1.000000 -0.080460 -0.666667  ... -0.333333  0.426357  0.449323  191\n",
              "1          1 -0.994460  0.218391 -0.500000  ... -0.333333  0.333333  0.462027  190\n",
              "2          1 -0.988920 -0.494253  0.500000  ... -0.666667  0.255814  0.242751  189\n",
              "3          1 -0.983380  0.080460  0.000000  ... -0.333333  0.147287  0.324772  188\n",
              "4          1 -0.977839 -0.218391 -0.333333  ... -0.166667  0.178295  0.409003  187\n",
              "5          1 -0.972299 -0.494253 -0.166667  ... -0.500000  0.302326  0.305440  186\n",
              "6          1 -0.966759  0.114943  0.166667  ... -0.333333  0.488372  0.334438  185\n",
              "7          1 -0.961219 -0.390805  0.500000  ... -0.500000  0.286822  0.149959  184\n",
              "8          1 -0.955679  0.091954  0.166667  ... -0.333333  0.410853  0.415079  183\n",
              "9          1 -0.950139 -0.379310  0.166667  ... -0.166667  0.255814  0.588511  182\n",
              "10         1 -0.944598  0.206897 -0.500000  ... -0.333333  0.240310  0.614195  181\n",
              "11         1 -0.939058  0.183908  0.333333  ... -0.500000  0.426357  0.302955  180\n",
              "12         1 -0.933518 -0.218391  0.666667  ... -0.166667  0.224806  0.053576  179\n",
              "13         1 -0.927978  0.103448  0.000000  ... -0.166667  0.612403  0.348799  178\n",
              "14         1 -0.922438 -0.206897 -0.500000  ... -0.500000  0.317829  0.258768  177\n",
              "15         1 -0.916898  0.068966  0.833333  ... -0.333333  0.286822  0.548743  176\n",
              "16         1 -0.911357  0.022989  0.333333  ... -0.333333  0.038760  0.208782  175\n",
              "17         1 -0.905817 -0.356322 -0.166667  ... -0.333333  0.162791  0.393262  174\n",
              "18         1 -0.900277  0.367816 -0.500000  ... -0.500000  0.023256  0.248826  173\n",
              "19         1 -0.894737 -0.425287  0.166667  ... -0.333333  0.379845  0.457608  172\n",
              "20         1 -0.889197 -0.137931  0.166667  ... -0.333333  0.472868  0.148578  171\n",
              "21         1 -0.883657  0.022989  0.000000  ... -0.333333  0.209302  0.339409  170\n",
              "22         1 -0.878116  0.390805 -0.500000  ... -0.333333  0.240310  0.552057  169\n",
              "23         1 -0.872576 -0.114943  0.500000  ... -0.333333  0.333333  0.312897  168\n",
              "24         1 -0.867036  0.264368 -0.666667  ... -0.166667  0.255814  0.476388  167\n",
              "25         1 -0.861496  0.000000  0.333333  ...  0.000000  0.116279  0.438001  166\n",
              "26         1 -0.855956 -0.137931 -0.666667  ... -0.166667  0.317829  0.527202  165\n",
              "27         1 -0.850416 -0.275862  0.833333  ... -0.666667  0.348837  0.076774  164\n",
              "28         1 -0.844875  0.137931 -0.166667  ... -0.166667  0.224806  0.285556  163\n",
              "29         1 -0.839335 -0.252874  0.000000  ... -0.666667  0.410853  0.427230  162\n",
              "\n",
              "[30 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqmN__iOXsWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_maps=np.empty((30,14,1))\n",
        "df_ys = np.zeros((1,1))\n",
        "for i in range(1,df['n_engine'].max()+1):\n",
        "  #se obtienen los dataset de engines independientes en df_temp\n",
        "  df_temp1 = df[df['n_engine'] == i]\n",
        "  df_temp2 = df_temp1.drop(['n_engine','cycle','opset_1','opset_2','opset_3'],axis=1)\n",
        "  df_features = df_temp2.drop(['RUL'],axis = 1)\n",
        "  df_y = df_temp2['RUL'].to_numpy()\n",
        "  df_ys = np.append(df_ys,df_y[29:])\n",
        "  for j in range(len(df_y)-29):\n",
        "    feature_map = df_features[j:j+30][:]\n",
        "    features_maps = np.dstack((features_maps, feature_map))\n",
        "features_maps=np.delete(features_maps, 0, 2)\n",
        "df_ys = np.delete(df_ys, 0, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwW_ULNgXsW2",
        "colab_type": "code",
        "outputId": "29859404-bf8a-4684-dd2c-d5fb6c4e6d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#como acceder a un feature map\n",
        "print(features_maps.shape)\n",
        "print(feature_map.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 14, 17731)\n",
            "(30, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnXLmy3taBHo",
        "colab_type": "code",
        "outputId": "fb44c80d-1967-4876-99de-eb7f7bcda081",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(df_ys.shape)\n",
        "print(df_y.shape)\n",
        "features_maps = np.moveaxis(features_maps, 2, 0)\n",
        "print(features_maps.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17731,)\n",
            "(200,)\n",
            "(17731, 30, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eL4RKvXPl7cr",
        "colab_type": "code",
        "outputId": "9db0f209-62c6-4bde-ddea-e474c8166990",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "df_ys = np.expand_dims(df_ys,axis=1)\n",
        "features_maps= np.expand_dims(features_maps,3)\n",
        "print(df_ys.shape)\n",
        "print(features_maps.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17731, 1)\n",
            "(17731, 30, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QWjmiljbKvZ",
        "colab_type": "code",
        "outputId": "8c3e4516-08f6-48ed-ca5c-ec013c1c859a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "features_maps, df_ys = shuffle(features_maps, df_ys, random_state=5)\n",
        "\n",
        "for i in range(len(df_ys)):\n",
        "  if df_ys[i] >= 125:\n",
        "    df_ys[i] = 125\n",
        "  else:\n",
        "    df_ys[i] = df_ys[i]\n",
        "\n",
        "print(df_ys)\n",
        "\n",
        "ys_train = df_ys[:int(len(df_ys)*0.9)]\n",
        "ys_valid = df_ys[int(len(df_ys)*0.9):]\n",
        "\n",
        "features_maps_train = features_maps[:int(len(df_ys)*0.9)]\n",
        "features_maps_valid = features_maps[int(len(df_ys)*0.9):]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[125.]\n",
            " [ 96.]\n",
            " [106.]\n",
            " ...\n",
            " [125.]\n",
            " [ 41.]\n",
            " [125.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34B0T27buS5J",
        "colab_type": "text"
      },
      "source": [
        "# CNN \n",
        "\n",
        "Propuesta de Li, Ding, Sun\n",
        "\n",
        "![Imagen](https://github.com/farayal/memoria_turbofan/blob/master/cnn_regression.png?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxtZOMIu2y7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "f0ecea1d-bef2-4812-900e-d4b6f7aa4064"
      },
      "source": [
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras import regularizers\n",
        "\n",
        "import keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Fc-VMlVNKso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnnturbofan(input_shape):\n",
        "   \n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    #Layer 1\n",
        "    # Zero-Padding: Para originar un output (20,14) en la siguiente capa\n",
        "    #X = ZeroPadding2D((5, 0))(X_input)\n",
        "\n",
        "    # CONV -> TANH aplicado a X\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1),padding='same', name = 'conv0')(X_input)\n",
        "    #X = BatchNormalization(axis = 3, name = 'bn0')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 2\n",
        "    #X = ZeroPadding2D((4, 0))(X)\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1), padding = 'same', name = 'conv1')(X)\n",
        "    #X = BatchNormalization(axis = 3, name = 'bn1')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 3\n",
        "    #X = ZeroPadding2D((5, 0))(X)\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1), padding='same', name = 'conv2')(X)\n",
        "    #X = BatchNormalization(axis = 3, name = 'bn2')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 4\n",
        "    #X = ZeroPadding2D((4, 0))(X)\n",
        "    X = Conv2D(10, (10, 1), strides = (1, 1),padding='same', name = 'conv3')(X)\n",
        "    #X = BatchNormalization(axis = 3, name = 'bn3')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    #Layer 5\n",
        "    #X = ZeroPadding2D((1, 0))(X)\n",
        "    X = Conv2D(1, (3, 1), strides = (1, 1),padding='same', name = 'conv4')(X)\n",
        "    #X = BatchNormalization(axis = 3, name = 'bn4')(X)\n",
        "    X = Activation('tanh')(X)\n",
        "\n",
        "    # FLATTEN X (\"desenrollamos el feature map anterior\") + FULLYCONNECTED\n",
        "    X = Flatten()(X)\n",
        "    X = Dropout(0.5)(X)\n",
        "    #X = BatchNormalization(name='bn5')(X)\n",
        "    X = Dense(100, activation='tanh', name='fully-connected')(X)\n",
        "    #X = Dropout(0.5)(X)\n",
        "    #X = BatchNormalization(name='bn6')(X)\n",
        "    X = Dense(1, name = 'rul-neuron')(X)\n",
        "\n",
        "    # instancia modelo final\n",
        "    model = Model(inputs = X_input, outputs = X, name='cnnturbofan')\n",
        "    \n",
        "  \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yRAWMhx1KoC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "bfbdb4e1-3d1a-4d39-e5d4-c1a06c7e39b1"
      },
      "source": [
        "cnnturbofan = cnnturbofan((features_maps.shape[1],features_maps.shape[2],features_maps.shape[3]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41z22sWe2W6d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9454503d-e252-4994-fd8f-c8fb4e20701a"
      },
      "source": [
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
        "\n",
        "cnnturbofan.compile(optimizer = \"Adam\", loss = \"mean_squared_error\" , metrics = [root_mean_squared_error])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmgEw6sw31M0",
        "colab_type": "code",
        "outputId": "13057756-f021-414a-8260-1969251cafce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = cnnturbofan.fit(x = features_maps_train, y = ys_train , epochs = 250 ,validation_data=(features_maps_valid,ys_valid))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 15957 samples, validate on 1774 samples\n",
            "Epoch 1/250\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "15957/15957 [==============================] - 13s 785us/step - loss: 3943.4021 - root_mean_squared_error: 61.7431 - val_loss: 2129.0241 - val_root_mean_squared_error: 45.9760\n",
            "Epoch 2/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 1294.7936 - root_mean_squared_error: 35.4252 - val_loss: 744.2675 - val_root_mean_squared_error: 27.1672\n",
            "Epoch 3/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 510.5871 - root_mean_squared_error: 22.3633 - val_loss: 366.1452 - val_root_mean_squared_error: 19.0506\n",
            "Epoch 4/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 294.4504 - root_mean_squared_error: 17.0268 - val_loss: 271.3002 - val_root_mean_squared_error: 16.3432\n",
            "Epoch 5/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 229.7878 - root_mean_squared_error: 15.0196 - val_loss: 191.3815 - val_root_mean_squared_error: 13.7510\n",
            "Epoch 6/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 201.0626 - root_mean_squared_error: 13.9897 - val_loss: 181.0591 - val_root_mean_squared_error: 13.3216\n",
            "Epoch 7/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 191.2084 - root_mean_squared_error: 13.6623 - val_loss: 167.0908 - val_root_mean_squared_error: 12.7868\n",
            "Epoch 8/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 183.1275 - root_mean_squared_error: 13.3442 - val_loss: 168.1518 - val_root_mean_squared_error: 12.8240\n",
            "Epoch 9/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 170.4178 - root_mean_squared_error: 12.8858 - val_loss: 168.7830 - val_root_mean_squared_error: 12.8594\n",
            "Epoch 10/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 167.2361 - root_mean_squared_error: 12.7814 - val_loss: 151.8025 - val_root_mean_squared_error: 12.1731\n",
            "Epoch 11/250\n",
            "15957/15957 [==============================] - 5s 340us/step - loss: 165.5211 - root_mean_squared_error: 12.6947 - val_loss: 162.0168 - val_root_mean_squared_error: 12.5635\n",
            "Epoch 12/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 163.7039 - root_mean_squared_error: 12.5906 - val_loss: 147.7687 - val_root_mean_squared_error: 12.0292\n",
            "Epoch 13/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 155.2721 - root_mean_squared_error: 12.3017 - val_loss: 146.8887 - val_root_mean_squared_error: 11.9688\n",
            "Epoch 14/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 153.4228 - root_mean_squared_error: 12.2010 - val_loss: 141.1315 - val_root_mean_squared_error: 11.7454\n",
            "Epoch 15/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 154.5218 - root_mean_squared_error: 12.2439 - val_loss: 148.3280 - val_root_mean_squared_error: 12.0581\n",
            "Epoch 16/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 152.5000 - root_mean_squared_error: 12.1765 - val_loss: 139.0368 - val_root_mean_squared_error: 11.6229\n",
            "Epoch 17/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 146.4156 - root_mean_squared_error: 11.9305 - val_loss: 138.8655 - val_root_mean_squared_error: 11.6271\n",
            "Epoch 18/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 145.2887 - root_mean_squared_error: 11.9003 - val_loss: 140.6847 - val_root_mean_squared_error: 11.7016\n",
            "Epoch 19/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 143.2546 - root_mean_squared_error: 11.8086 - val_loss: 131.8012 - val_root_mean_squared_error: 11.3231\n",
            "Epoch 20/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 142.5604 - root_mean_squared_error: 11.7868 - val_loss: 130.5638 - val_root_mean_squared_error: 11.2609\n",
            "Epoch 21/250\n",
            "15957/15957 [==============================] - 5s 340us/step - loss: 139.3044 - root_mean_squared_error: 11.6268 - val_loss: 127.5530 - val_root_mean_squared_error: 11.1551\n",
            "Epoch 22/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 139.0801 - root_mean_squared_error: 11.6235 - val_loss: 157.3224 - val_root_mean_squared_error: 12.3568\n",
            "Epoch 23/250\n",
            "15957/15957 [==============================] - 5s 340us/step - loss: 137.1328 - root_mean_squared_error: 11.5588 - val_loss: 123.9294 - val_root_mean_squared_error: 10.9781\n",
            "Epoch 24/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 138.3874 - root_mean_squared_error: 11.6098 - val_loss: 120.0713 - val_root_mean_squared_error: 10.8213\n",
            "Epoch 25/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 131.7529 - root_mean_squared_error: 11.3101 - val_loss: 123.0857 - val_root_mean_squared_error: 10.9406\n",
            "Epoch 26/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 134.6466 - root_mean_squared_error: 11.4356 - val_loss: 150.9092 - val_root_mean_squared_error: 12.1023\n",
            "Epoch 27/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 132.5518 - root_mean_squared_error: 11.3510 - val_loss: 118.1836 - val_root_mean_squared_error: 10.7173\n",
            "Epoch 28/250\n",
            "15957/15957 [==============================] - 5s 340us/step - loss: 133.7508 - root_mean_squared_error: 11.3968 - val_loss: 142.9192 - val_root_mean_squared_error: 11.7754\n",
            "Epoch 29/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 129.3813 - root_mean_squared_error: 11.2190 - val_loss: 119.9341 - val_root_mean_squared_error: 10.8145\n",
            "Epoch 30/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 129.6293 - root_mean_squared_error: 11.2138 - val_loss: 117.1320 - val_root_mean_squared_error: 10.6550\n",
            "Epoch 31/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 127.0781 - root_mean_squared_error: 11.1102 - val_loss: 117.1181 - val_root_mean_squared_error: 10.6558\n",
            "Epoch 32/250\n",
            "15957/15957 [==============================] - 6s 348us/step - loss: 126.5371 - root_mean_squared_error: 11.0876 - val_loss: 145.8752 - val_root_mean_squared_error: 11.8770\n",
            "Epoch 33/250\n",
            "15957/15957 [==============================] - 6s 348us/step - loss: 125.7047 - root_mean_squared_error: 11.0521 - val_loss: 127.3146 - val_root_mean_squared_error: 11.1009\n",
            "Epoch 34/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 126.6840 - root_mean_squared_error: 11.0921 - val_loss: 116.0881 - val_root_mean_squared_error: 10.6250\n",
            "Epoch 35/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 125.8830 - root_mean_squared_error: 11.0588 - val_loss: 123.0228 - val_root_mean_squared_error: 10.9205\n",
            "Epoch 36/250\n",
            "15957/15957 [==============================] - 5s 342us/step - loss: 128.1623 - root_mean_squared_error: 11.1529 - val_loss: 139.8404 - val_root_mean_squared_error: 11.6268\n",
            "Epoch 37/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 123.4543 - root_mean_squared_error: 10.9466 - val_loss: 116.8076 - val_root_mean_squared_error: 10.6504\n",
            "Epoch 38/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 121.2258 - root_mean_squared_error: 10.8615 - val_loss: 123.0563 - val_root_mean_squared_error: 10.9334\n",
            "Epoch 39/250\n",
            "15957/15957 [==============================] - 6s 350us/step - loss: 120.8855 - root_mean_squared_error: 10.8364 - val_loss: 118.0607 - val_root_mean_squared_error: 10.6844\n",
            "Epoch 40/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 120.7780 - root_mean_squared_error: 10.8290 - val_loss: 106.2891 - val_root_mean_squared_error: 10.1359\n",
            "Epoch 41/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 118.3823 - root_mean_squared_error: 10.7229 - val_loss: 105.6091 - val_root_mean_squared_error: 10.1114\n",
            "Epoch 42/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 118.7919 - root_mean_squared_error: 10.7302 - val_loss: 108.6543 - val_root_mean_squared_error: 10.2530\n",
            "Epoch 43/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 119.3910 - root_mean_squared_error: 10.7527 - val_loss: 107.7125 - val_root_mean_squared_error: 10.2321\n",
            "Epoch 44/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 119.2869 - root_mean_squared_error: 10.7670 - val_loss: 122.4876 - val_root_mean_squared_error: 10.8657\n",
            "Epoch 45/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 116.5328 - root_mean_squared_error: 10.6340 - val_loss: 102.0870 - val_root_mean_squared_error: 9.9122\n",
            "Epoch 46/250\n",
            "15957/15957 [==============================] - 5s 340us/step - loss: 114.3224 - root_mean_squared_error: 10.5287 - val_loss: 112.2571 - val_root_mean_squared_error: 10.4532\n",
            "Epoch 47/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 114.8330 - root_mean_squared_error: 10.5855 - val_loss: 104.5776 - val_root_mean_squared_error: 10.0566\n",
            "Epoch 48/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 114.5261 - root_mean_squared_error: 10.5443 - val_loss: 99.7092 - val_root_mean_squared_error: 9.8401\n",
            "Epoch 49/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 114.3566 - root_mean_squared_error: 10.5393 - val_loss: 100.6407 - val_root_mean_squared_error: 9.8728\n",
            "Epoch 50/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 112.0847 - root_mean_squared_error: 10.4358 - val_loss: 97.5825 - val_root_mean_squared_error: 9.7212\n",
            "Epoch 51/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 113.4044 - root_mean_squared_error: 10.4908 - val_loss: 108.1636 - val_root_mean_squared_error: 10.2233\n",
            "Epoch 52/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 109.8022 - root_mean_squared_error: 10.3266 - val_loss: 95.2410 - val_root_mean_squared_error: 9.5980\n",
            "Epoch 53/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 110.1070 - root_mean_squared_error: 10.3400 - val_loss: 97.2387 - val_root_mean_squared_error: 9.7015\n",
            "Epoch 54/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 109.0323 - root_mean_squared_error: 10.2939 - val_loss: 95.2219 - val_root_mean_squared_error: 9.5871\n",
            "Epoch 55/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 109.4513 - root_mean_squared_error: 10.3152 - val_loss: 94.2536 - val_root_mean_squared_error: 9.5554\n",
            "Epoch 56/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 108.0192 - root_mean_squared_error: 10.2395 - val_loss: 99.6412 - val_root_mean_squared_error: 9.8103\n",
            "Epoch 57/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 108.7560 - root_mean_squared_error: 10.2717 - val_loss: 92.6389 - val_root_mean_squared_error: 9.4697\n",
            "Epoch 58/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 108.0447 - root_mean_squared_error: 10.2318 - val_loss: 109.4231 - val_root_mean_squared_error: 10.2967\n",
            "Epoch 59/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 106.5771 - root_mean_squared_error: 10.1690 - val_loss: 96.3039 - val_root_mean_squared_error: 9.6243\n",
            "Epoch 60/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 105.3132 - root_mean_squared_error: 10.1227 - val_loss: 96.0308 - val_root_mean_squared_error: 9.6180\n",
            "Epoch 61/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 105.0550 - root_mean_squared_error: 10.1081 - val_loss: 102.8753 - val_root_mean_squared_error: 9.9682\n",
            "Epoch 62/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 101.4842 - root_mean_squared_error: 9.9277 - val_loss: 94.9877 - val_root_mean_squared_error: 9.5908\n",
            "Epoch 63/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 103.7332 - root_mean_squared_error: 10.0481 - val_loss: 90.3465 - val_root_mean_squared_error: 9.3473\n",
            "Epoch 64/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 105.1162 - root_mean_squared_error: 10.1052 - val_loss: 90.0356 - val_root_mean_squared_error: 9.3139\n",
            "Epoch 65/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 103.2672 - root_mean_squared_error: 10.0061 - val_loss: 97.8778 - val_root_mean_squared_error: 9.7079\n",
            "Epoch 66/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 101.1274 - root_mean_squared_error: 9.8981 - val_loss: 103.5885 - val_root_mean_squared_error: 9.9988\n",
            "Epoch 67/250\n",
            "15957/15957 [==============================] - 5s 328us/step - loss: 99.9400 - root_mean_squared_error: 9.8405 - val_loss: 91.5682 - val_root_mean_squared_error: 9.4136\n",
            "Epoch 68/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 98.5738 - root_mean_squared_error: 9.7817 - val_loss: 86.4400 - val_root_mean_squared_error: 9.1325\n",
            "Epoch 69/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 100.3171 - root_mean_squared_error: 9.8638 - val_loss: 83.7309 - val_root_mean_squared_error: 8.9979\n",
            "Epoch 70/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 97.5569 - root_mean_squared_error: 9.7208 - val_loss: 81.6059 - val_root_mean_squared_error: 8.8648\n",
            "Epoch 71/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 96.7928 - root_mean_squared_error: 9.7004 - val_loss: 83.6745 - val_root_mean_squared_error: 8.9739\n",
            "Epoch 72/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 94.1846 - root_mean_squared_error: 9.5502 - val_loss: 81.8903 - val_root_mean_squared_error: 8.9004\n",
            "Epoch 73/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 95.5910 - root_mean_squared_error: 9.6401 - val_loss: 83.5898 - val_root_mean_squared_error: 8.9844\n",
            "Epoch 74/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 95.6204 - root_mean_squared_error: 9.6359 - val_loss: 80.2095 - val_root_mean_squared_error: 8.7717\n",
            "Epoch 75/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 93.3846 - root_mean_squared_error: 9.5350 - val_loss: 79.5017 - val_root_mean_squared_error: 8.7682\n",
            "Epoch 76/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 93.0367 - root_mean_squared_error: 9.4992 - val_loss: 79.0697 - val_root_mean_squared_error: 8.7339\n",
            "Epoch 77/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 92.9107 - root_mean_squared_error: 9.4954 - val_loss: 80.6886 - val_root_mean_squared_error: 8.7962\n",
            "Epoch 78/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 92.7093 - root_mean_squared_error: 9.4932 - val_loss: 83.6904 - val_root_mean_squared_error: 8.9635\n",
            "Epoch 79/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 90.7728 - root_mean_squared_error: 9.3878 - val_loss: 75.0909 - val_root_mean_squared_error: 8.4925\n",
            "Epoch 80/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 89.1722 - root_mean_squared_error: 9.3058 - val_loss: 76.2563 - val_root_mean_squared_error: 8.5823\n",
            "Epoch 81/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 90.5246 - root_mean_squared_error: 9.3750 - val_loss: 74.1761 - val_root_mean_squared_error: 8.4696\n",
            "Epoch 82/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 89.0336 - root_mean_squared_error: 9.3095 - val_loss: 89.0661 - val_root_mean_squared_error: 9.2612\n",
            "Epoch 83/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 88.0607 - root_mean_squared_error: 9.2455 - val_loss: 76.3675 - val_root_mean_squared_error: 8.5913\n",
            "Epoch 84/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 87.4783 - root_mean_squared_error: 9.2084 - val_loss: 73.4044 - val_root_mean_squared_error: 8.4189\n",
            "Epoch 85/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 84.8828 - root_mean_squared_error: 9.0678 - val_loss: 76.5635 - val_root_mean_squared_error: 8.6027\n",
            "Epoch 86/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 85.8961 - root_mean_squared_error: 9.1327 - val_loss: 75.9206 - val_root_mean_squared_error: 8.5562\n",
            "Epoch 87/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 84.4027 - root_mean_squared_error: 9.0502 - val_loss: 79.5459 - val_root_mean_squared_error: 8.7740\n",
            "Epoch 88/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 85.6686 - root_mean_squared_error: 9.1204 - val_loss: 75.0228 - val_root_mean_squared_error: 8.5055\n",
            "Epoch 89/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 83.1902 - root_mean_squared_error: 8.9912 - val_loss: 73.1639 - val_root_mean_squared_error: 8.4100\n",
            "Epoch 90/250\n",
            "15957/15957 [==============================] - 6s 351us/step - loss: 81.7567 - root_mean_squared_error: 8.9164 - val_loss: 68.2481 - val_root_mean_squared_error: 8.1241\n",
            "Epoch 91/250\n",
            "15957/15957 [==============================] - 5s 343us/step - loss: 82.3375 - root_mean_squared_error: 8.9435 - val_loss: 69.5778 - val_root_mean_squared_error: 8.1992\n",
            "Epoch 92/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 81.1057 - root_mean_squared_error: 8.8781 - val_loss: 76.0393 - val_root_mean_squared_error: 8.5621\n",
            "Epoch 93/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 80.0121 - root_mean_squared_error: 8.8294 - val_loss: 73.4646 - val_root_mean_squared_error: 8.4228\n",
            "Epoch 94/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 77.8530 - root_mean_squared_error: 8.6850 - val_loss: 72.5123 - val_root_mean_squared_error: 8.3629\n",
            "Epoch 95/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 78.3288 - root_mean_squared_error: 8.7236 - val_loss: 65.2503 - val_root_mean_squared_error: 7.9568\n",
            "Epoch 96/250\n",
            "15957/15957 [==============================] - 6s 347us/step - loss: 78.5622 - root_mean_squared_error: 8.7407 - val_loss: 66.1646 - val_root_mean_squared_error: 8.0008\n",
            "Epoch 97/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 77.2091 - root_mean_squared_error: 8.6480 - val_loss: 68.1983 - val_root_mean_squared_error: 8.1253\n",
            "Epoch 98/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 78.1890 - root_mean_squared_error: 8.7105 - val_loss: 68.2610 - val_root_mean_squared_error: 8.0964\n",
            "Epoch 99/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 75.3888 - root_mean_squared_error: 8.5586 - val_loss: 63.6052 - val_root_mean_squared_error: 7.8414\n",
            "Epoch 100/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 74.0834 - root_mean_squared_error: 8.4826 - val_loss: 61.4591 - val_root_mean_squared_error: 7.7232\n",
            "Epoch 101/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 74.9680 - root_mean_squared_error: 8.5186 - val_loss: 61.9157 - val_root_mean_squared_error: 7.7607\n",
            "Epoch 102/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 76.7714 - root_mean_squared_error: 8.6368 - val_loss: 64.7599 - val_root_mean_squared_error: 7.9339\n",
            "Epoch 103/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 75.1044 - root_mean_squared_error: 8.5296 - val_loss: 60.4129 - val_root_mean_squared_error: 7.6651\n",
            "Epoch 104/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 74.5664 - root_mean_squared_error: 8.5006 - val_loss: 62.5500 - val_root_mean_squared_error: 7.7731\n",
            "Epoch 105/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 72.9820 - root_mean_squared_error: 8.4191 - val_loss: 71.6864 - val_root_mean_squared_error: 8.3364\n",
            "Epoch 106/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 71.3426 - root_mean_squared_error: 8.3156 - val_loss: 64.4559 - val_root_mean_squared_error: 7.8975\n",
            "Epoch 107/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 70.6006 - root_mean_squared_error: 8.2731 - val_loss: 73.2065 - val_root_mean_squared_error: 8.4293\n",
            "Epoch 108/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 72.0381 - root_mean_squared_error: 8.3556 - val_loss: 59.0042 - val_root_mean_squared_error: 7.5884\n",
            "Epoch 109/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 70.0772 - root_mean_squared_error: 8.2370 - val_loss: 58.5501 - val_root_mean_squared_error: 7.5468\n",
            "Epoch 110/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 69.0496 - root_mean_squared_error: 8.1887 - val_loss: 64.8116 - val_root_mean_squared_error: 7.9270\n",
            "Epoch 111/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 70.8465 - root_mean_squared_error: 8.3021 - val_loss: 59.7759 - val_root_mean_squared_error: 7.6211\n",
            "Epoch 112/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 69.8024 - root_mean_squared_error: 8.2190 - val_loss: 60.5696 - val_root_mean_squared_error: 7.6869\n",
            "Epoch 113/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 67.8080 - root_mean_squared_error: 8.1044 - val_loss: 56.0558 - val_root_mean_squared_error: 7.3728\n",
            "Epoch 114/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 67.4867 - root_mean_squared_error: 8.0941 - val_loss: 55.4353 - val_root_mean_squared_error: 7.3531\n",
            "Epoch 115/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 68.0444 - root_mean_squared_error: 8.1359 - val_loss: 54.8854 - val_root_mean_squared_error: 7.2987\n",
            "Epoch 116/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 65.1621 - root_mean_squared_error: 7.9521 - val_loss: 57.1275 - val_root_mean_squared_error: 7.4409\n",
            "Epoch 117/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 67.8954 - root_mean_squared_error: 8.1077 - val_loss: 52.6178 - val_root_mean_squared_error: 7.1536\n",
            "Epoch 118/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 64.9781 - root_mean_squared_error: 7.9358 - val_loss: 52.7592 - val_root_mean_squared_error: 7.1593\n",
            "Epoch 119/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 66.7888 - root_mean_squared_error: 8.0474 - val_loss: 53.8826 - val_root_mean_squared_error: 7.2448\n",
            "Epoch 120/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 65.0311 - root_mean_squared_error: 7.9434 - val_loss: 68.1391 - val_root_mean_squared_error: 8.1431\n",
            "Epoch 121/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 64.5508 - root_mean_squared_error: 7.9117 - val_loss: 73.2769 - val_root_mean_squared_error: 8.4379\n",
            "Epoch 122/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 63.3316 - root_mean_squared_error: 7.8497 - val_loss: 54.2153 - val_root_mean_squared_error: 7.2598\n",
            "Epoch 123/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 64.9720 - root_mean_squared_error: 7.9278 - val_loss: 50.1011 - val_root_mean_squared_error: 6.9795\n",
            "Epoch 124/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 64.2668 - root_mean_squared_error: 7.8904 - val_loss: 63.2702 - val_root_mean_squared_error: 7.8042\n",
            "Epoch 125/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 62.3947 - root_mean_squared_error: 7.7882 - val_loss: 49.2571 - val_root_mean_squared_error: 6.9205\n",
            "Epoch 126/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 62.6146 - root_mean_squared_error: 7.7991 - val_loss: 49.0463 - val_root_mean_squared_error: 6.9161\n",
            "Epoch 127/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 62.1349 - root_mean_squared_error: 7.7712 - val_loss: 55.9906 - val_root_mean_squared_error: 7.3690\n",
            "Epoch 128/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 60.4434 - root_mean_squared_error: 7.6548 - val_loss: 51.8240 - val_root_mean_squared_error: 7.1067\n",
            "Epoch 129/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 61.4191 - root_mean_squared_error: 7.7213 - val_loss: 45.1607 - val_root_mean_squared_error: 6.6409\n",
            "Epoch 130/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 61.3121 - root_mean_squared_error: 7.7091 - val_loss: 55.3085 - val_root_mean_squared_error: 7.3280\n",
            "Epoch 131/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 60.4925 - root_mean_squared_error: 7.6614 - val_loss: 55.3837 - val_root_mean_squared_error: 7.3200\n",
            "Epoch 132/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 58.5321 - root_mean_squared_error: 7.5349 - val_loss: 51.9327 - val_root_mean_squared_error: 7.0939\n",
            "Epoch 133/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 60.6612 - root_mean_squared_error: 7.6650 - val_loss: 44.0004 - val_root_mean_squared_error: 6.5602\n",
            "Epoch 134/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 59.3523 - root_mean_squared_error: 7.5756 - val_loss: 41.6264 - val_root_mean_squared_error: 6.3662\n",
            "Epoch 135/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 58.3350 - root_mean_squared_error: 7.5221 - val_loss: 45.2988 - val_root_mean_squared_error: 6.6534\n",
            "Epoch 136/250\n",
            "15957/15957 [==============================] - 5s 329us/step - loss: 57.1819 - root_mean_squared_error: 7.4477 - val_loss: 41.7314 - val_root_mean_squared_error: 6.3864\n",
            "Epoch 137/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 57.6469 - root_mean_squared_error: 7.4865 - val_loss: 48.3941 - val_root_mean_squared_error: 6.8728\n",
            "Epoch 138/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 58.4339 - root_mean_squared_error: 7.5308 - val_loss: 50.6329 - val_root_mean_squared_error: 7.0031\n",
            "Epoch 139/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 58.0629 - root_mean_squared_error: 7.5196 - val_loss: 53.6501 - val_root_mean_squared_error: 7.2371\n",
            "Epoch 140/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 55.9011 - root_mean_squared_error: 7.3802 - val_loss: 46.7606 - val_root_mean_squared_error: 6.7458\n",
            "Epoch 141/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 56.0201 - root_mean_squared_error: 7.3832 - val_loss: 45.9669 - val_root_mean_squared_error: 6.6789\n",
            "Epoch 142/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 56.7630 - root_mean_squared_error: 7.4421 - val_loss: 42.2805 - val_root_mean_squared_error: 6.4234\n",
            "Epoch 143/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 54.7313 - root_mean_squared_error: 7.2829 - val_loss: 43.5044 - val_root_mean_squared_error: 6.5187\n",
            "Epoch 144/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 56.2649 - root_mean_squared_error: 7.3952 - val_loss: 46.6129 - val_root_mean_squared_error: 6.7311\n",
            "Epoch 145/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 54.3790 - root_mean_squared_error: 7.2696 - val_loss: 39.9255 - val_root_mean_squared_error: 6.2455\n",
            "Epoch 146/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 56.3399 - root_mean_squared_error: 7.3949 - val_loss: 41.9600 - val_root_mean_squared_error: 6.3961\n",
            "Epoch 147/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 54.8051 - root_mean_squared_error: 7.2927 - val_loss: 45.1766 - val_root_mean_squared_error: 6.6417\n",
            "Epoch 148/250\n",
            "15957/15957 [==============================] - 6s 347us/step - loss: 55.2612 - root_mean_squared_error: 7.3216 - val_loss: 38.2120 - val_root_mean_squared_error: 6.0888\n",
            "Epoch 149/250\n",
            "15957/15957 [==============================] - 6s 347us/step - loss: 53.5190 - root_mean_squared_error: 7.2161 - val_loss: 45.5326 - val_root_mean_squared_error: 6.6411\n",
            "Epoch 150/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 52.3453 - root_mean_squared_error: 7.1211 - val_loss: 41.8524 - val_root_mean_squared_error: 6.3884\n",
            "Epoch 151/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 53.1555 - root_mean_squared_error: 7.1932 - val_loss: 38.4254 - val_root_mean_squared_error: 6.1248\n",
            "Epoch 152/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 52.1081 - root_mean_squared_error: 7.1182 - val_loss: 41.8326 - val_root_mean_squared_error: 6.3831\n",
            "Epoch 153/250\n",
            "15957/15957 [==============================] - 6s 347us/step - loss: 53.7695 - root_mean_squared_error: 7.2327 - val_loss: 39.9638 - val_root_mean_squared_error: 6.2283\n",
            "Epoch 154/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 53.2775 - root_mean_squared_error: 7.2008 - val_loss: 40.5955 - val_root_mean_squared_error: 6.2704\n",
            "Epoch 155/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 51.1275 - root_mean_squared_error: 7.0454 - val_loss: 37.7202 - val_root_mean_squared_error: 6.0457\n",
            "Epoch 156/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 50.5458 - root_mean_squared_error: 7.0063 - val_loss: 37.8531 - val_root_mean_squared_error: 6.0559\n",
            "Epoch 157/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 52.4234 - root_mean_squared_error: 7.1285 - val_loss: 36.6099 - val_root_mean_squared_error: 5.9553\n",
            "Epoch 158/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 51.3820 - root_mean_squared_error: 7.0640 - val_loss: 37.4546 - val_root_mean_squared_error: 6.0317\n",
            "Epoch 159/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 50.8168 - root_mean_squared_error: 7.0199 - val_loss: 48.3673 - val_root_mean_squared_error: 6.8581\n",
            "Epoch 160/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 50.8798 - root_mean_squared_error: 7.0165 - val_loss: 49.7296 - val_root_mean_squared_error: 6.9262\n",
            "Epoch 161/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 50.0806 - root_mean_squared_error: 6.9781 - val_loss: 38.6175 - val_root_mean_squared_error: 6.1352\n",
            "Epoch 162/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 50.9190 - root_mean_squared_error: 7.0235 - val_loss: 38.6448 - val_root_mean_squared_error: 6.1187\n",
            "Epoch 163/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 50.3062 - root_mean_squared_error: 6.9878 - val_loss: 38.7890 - val_root_mean_squared_error: 6.1426\n",
            "Epoch 164/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 49.7114 - root_mean_squared_error: 6.9443 - val_loss: 42.7225 - val_root_mean_squared_error: 6.4417\n",
            "Epoch 165/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 48.5299 - root_mean_squared_error: 6.8669 - val_loss: 35.2473 - val_root_mean_squared_error: 5.8731\n",
            "Epoch 166/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 49.5367 - root_mean_squared_error: 6.9234 - val_loss: 37.7631 - val_root_mean_squared_error: 6.0689\n",
            "Epoch 167/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 49.0296 - root_mean_squared_error: 6.8981 - val_loss: 38.9447 - val_root_mean_squared_error: 6.1465\n",
            "Epoch 168/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 48.1119 - root_mean_squared_error: 6.8420 - val_loss: 43.2892 - val_root_mean_squared_error: 6.4701\n",
            "Epoch 169/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 50.1836 - root_mean_squared_error: 6.9792 - val_loss: 36.3301 - val_root_mean_squared_error: 5.9506\n",
            "Epoch 170/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 48.0333 - root_mean_squared_error: 6.8324 - val_loss: 35.8972 - val_root_mean_squared_error: 5.8904\n",
            "Epoch 171/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 49.2102 - root_mean_squared_error: 6.9029 - val_loss: 35.6579 - val_root_mean_squared_error: 5.8857\n",
            "Epoch 172/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 46.7445 - root_mean_squared_error: 6.7388 - val_loss: 37.4598 - val_root_mean_squared_error: 6.0286\n",
            "Epoch 173/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 48.4264 - root_mean_squared_error: 6.8642 - val_loss: 34.8825 - val_root_mean_squared_error: 5.8240\n",
            "Epoch 174/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 47.7540 - root_mean_squared_error: 6.8058 - val_loss: 35.1798 - val_root_mean_squared_error: 5.8445\n",
            "Epoch 175/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 47.2531 - root_mean_squared_error: 6.7812 - val_loss: 33.7369 - val_root_mean_squared_error: 5.7085\n",
            "Epoch 176/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 46.7660 - root_mean_squared_error: 6.7451 - val_loss: 33.9478 - val_root_mean_squared_error: 5.7260\n",
            "Epoch 177/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 47.0233 - root_mean_squared_error: 6.7501 - val_loss: 31.1463 - val_root_mean_squared_error: 5.5007\n",
            "Epoch 178/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 46.2125 - root_mean_squared_error: 6.6987 - val_loss: 39.0922 - val_root_mean_squared_error: 6.1493\n",
            "Epoch 179/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 46.5073 - root_mean_squared_error: 6.7238 - val_loss: 37.3762 - val_root_mean_squared_error: 6.0118\n",
            "Epoch 180/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 47.7746 - root_mean_squared_error: 6.8210 - val_loss: 33.9191 - val_root_mean_squared_error: 5.7475\n",
            "Epoch 181/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 46.0654 - root_mean_squared_error: 6.6899 - val_loss: 41.5824 - val_root_mean_squared_error: 6.3369\n",
            "Epoch 182/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 44.7978 - root_mean_squared_error: 6.5954 - val_loss: 35.0552 - val_root_mean_squared_error: 5.8216\n",
            "Epoch 183/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 46.5818 - root_mean_squared_error: 6.7322 - val_loss: 35.5786 - val_root_mean_squared_error: 5.8581\n",
            "Epoch 184/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 45.7061 - root_mean_squared_error: 6.6587 - val_loss: 35.4218 - val_root_mean_squared_error: 5.8451\n",
            "Epoch 185/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 45.4775 - root_mean_squared_error: 6.6524 - val_loss: 35.6402 - val_root_mean_squared_error: 5.8709\n",
            "Epoch 186/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 45.8563 - root_mean_squared_error: 6.6622 - val_loss: 37.8443 - val_root_mean_squared_error: 6.0492\n",
            "Epoch 187/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 43.6892 - root_mean_squared_error: 6.5074 - val_loss: 36.8297 - val_root_mean_squared_error: 5.9478\n",
            "Epoch 188/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 44.1269 - root_mean_squared_error: 6.5378 - val_loss: 33.5207 - val_root_mean_squared_error: 5.6996\n",
            "Epoch 189/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 45.0789 - root_mean_squared_error: 6.6203 - val_loss: 36.2479 - val_root_mean_squared_error: 5.9275\n",
            "Epoch 190/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 43.0981 - root_mean_squared_error: 6.4708 - val_loss: 31.1280 - val_root_mean_squared_error: 5.4801\n",
            "Epoch 191/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 43.7077 - root_mean_squared_error: 6.5136 - val_loss: 32.4576 - val_root_mean_squared_error: 5.6034\n",
            "Epoch 192/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 44.2505 - root_mean_squared_error: 6.5527 - val_loss: 32.8357 - val_root_mean_squared_error: 5.6386\n",
            "Epoch 193/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 44.9136 - root_mean_squared_error: 6.6058 - val_loss: 38.5957 - val_root_mean_squared_error: 6.1021\n",
            "Epoch 194/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 43.7155 - root_mean_squared_error: 6.5108 - val_loss: 42.9841 - val_root_mean_squared_error: 6.4559\n",
            "Epoch 195/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 43.8212 - root_mean_squared_error: 6.5274 - val_loss: 32.7674 - val_root_mean_squared_error: 5.6279\n",
            "Epoch 196/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 43.8356 - root_mean_squared_error: 6.5131 - val_loss: 35.3578 - val_root_mean_squared_error: 5.8645\n",
            "Epoch 197/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 43.3846 - root_mean_squared_error: 6.4799 - val_loss: 31.3521 - val_root_mean_squared_error: 5.5050\n",
            "Epoch 198/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 43.1375 - root_mean_squared_error: 6.4790 - val_loss: 36.6125 - val_root_mean_squared_error: 5.9520\n",
            "Epoch 199/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 44.1317 - root_mean_squared_error: 6.5453 - val_loss: 31.3172 - val_root_mean_squared_error: 5.4999\n",
            "Epoch 200/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 42.2988 - root_mean_squared_error: 6.4044 - val_loss: 42.9634 - val_root_mean_squared_error: 6.4639\n",
            "Epoch 201/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 43.3205 - root_mean_squared_error: 6.4780 - val_loss: 30.1774 - val_root_mean_squared_error: 5.3844\n",
            "Epoch 202/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 43.1717 - root_mean_squared_error: 6.4677 - val_loss: 37.4609 - val_root_mean_squared_error: 6.0251\n",
            "Epoch 203/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 42.7510 - root_mean_squared_error: 6.4424 - val_loss: 30.4325 - val_root_mean_squared_error: 5.4092\n",
            "Epoch 204/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 40.8398 - root_mean_squared_error: 6.2959 - val_loss: 39.9569 - val_root_mean_squared_error: 6.2229\n",
            "Epoch 205/250\n",
            "15957/15957 [==============================] - 5s 337us/step - loss: 42.1580 - root_mean_squared_error: 6.3862 - val_loss: 32.8782 - val_root_mean_squared_error: 5.6416\n",
            "Epoch 206/250\n",
            "15957/15957 [==============================] - 6s 347us/step - loss: 41.6765 - root_mean_squared_error: 6.3653 - val_loss: 29.9440 - val_root_mean_squared_error: 5.3856\n",
            "Epoch 207/250\n",
            "15957/15957 [==============================] - 6s 348us/step - loss: 41.9967 - root_mean_squared_error: 6.3873 - val_loss: 29.1446 - val_root_mean_squared_error: 5.3146\n",
            "Epoch 208/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 41.5151 - root_mean_squared_error: 6.3471 - val_loss: 39.3282 - val_root_mean_squared_error: 6.1634\n",
            "Epoch 209/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 42.1695 - root_mean_squared_error: 6.3946 - val_loss: 35.2717 - val_root_mean_squared_error: 5.8378\n",
            "Epoch 210/250\n",
            "15957/15957 [==============================] - 5s 344us/step - loss: 40.3967 - root_mean_squared_error: 6.2667 - val_loss: 30.3619 - val_root_mean_squared_error: 5.4160\n",
            "Epoch 211/250\n",
            "15957/15957 [==============================] - 5s 339us/step - loss: 41.2787 - root_mean_squared_error: 6.3177 - val_loss: 29.4144 - val_root_mean_squared_error: 5.3292\n",
            "Epoch 212/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 41.8582 - root_mean_squared_error: 6.3708 - val_loss: 30.7914 - val_root_mean_squared_error: 5.4593\n",
            "Epoch 213/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 41.1394 - root_mean_squared_error: 6.3116 - val_loss: 36.3078 - val_root_mean_squared_error: 5.9259\n",
            "Epoch 214/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 41.2642 - root_mean_squared_error: 6.3310 - val_loss: 35.3467 - val_root_mean_squared_error: 5.8431\n",
            "Epoch 215/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 41.2967 - root_mean_squared_error: 6.3301 - val_loss: 29.1426 - val_root_mean_squared_error: 5.3183\n",
            "Epoch 216/250\n",
            "15957/15957 [==============================] - 5s 338us/step - loss: 41.2344 - root_mean_squared_error: 6.3272 - val_loss: 28.3667 - val_root_mean_squared_error: 5.2386\n",
            "Epoch 217/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 40.2397 - root_mean_squared_error: 6.2591 - val_loss: 30.2736 - val_root_mean_squared_error: 5.4171\n",
            "Epoch 218/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 39.9968 - root_mean_squared_error: 6.2380 - val_loss: 28.6139 - val_root_mean_squared_error: 5.2602\n",
            "Epoch 219/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 40.0241 - root_mean_squared_error: 6.2253 - val_loss: 30.5713 - val_root_mean_squared_error: 5.4290\n",
            "Epoch 220/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 40.0591 - root_mean_squared_error: 6.2331 - val_loss: 30.9665 - val_root_mean_squared_error: 5.4732\n",
            "Epoch 221/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 41.0023 - root_mean_squared_error: 6.3092 - val_loss: 29.0211 - val_root_mean_squared_error: 5.2948\n",
            "Epoch 222/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 38.9515 - root_mean_squared_error: 6.1534 - val_loss: 31.1666 - val_root_mean_squared_error: 5.4920\n",
            "Epoch 223/250\n",
            "15957/15957 [==============================] - 5s 335us/step - loss: 39.4496 - root_mean_squared_error: 6.1954 - val_loss: 33.6045 - val_root_mean_squared_error: 5.6875\n",
            "Epoch 224/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 40.5009 - root_mean_squared_error: 6.2768 - val_loss: 27.8227 - val_root_mean_squared_error: 5.2133\n",
            "Epoch 225/250\n",
            "15957/15957 [==============================] - 5s 336us/step - loss: 39.7492 - root_mean_squared_error: 6.2117 - val_loss: 32.5624 - val_root_mean_squared_error: 5.6122\n",
            "Epoch 226/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 38.7950 - root_mean_squared_error: 6.1410 - val_loss: 30.4673 - val_root_mean_squared_error: 5.4123\n",
            "Epoch 227/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 39.3816 - root_mean_squared_error: 6.1864 - val_loss: 30.9258 - val_root_mean_squared_error: 5.4541\n",
            "Epoch 228/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 38.7767 - root_mean_squared_error: 6.1295 - val_loss: 27.4809 - val_root_mean_squared_error: 5.1718\n",
            "Epoch 229/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 40.1973 - root_mean_squared_error: 6.2509 - val_loss: 28.7691 - val_root_mean_squared_error: 5.2732\n",
            "Epoch 230/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 39.5928 - root_mean_squared_error: 6.1971 - val_loss: 27.8273 - val_root_mean_squared_error: 5.1842\n",
            "Epoch 231/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 39.1762 - root_mean_squared_error: 6.1727 - val_loss: 29.0985 - val_root_mean_squared_error: 5.2915\n",
            "Epoch 232/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 38.9505 - root_mean_squared_error: 6.1506 - val_loss: 29.4125 - val_root_mean_squared_error: 5.3283\n",
            "Epoch 233/250\n",
            "15957/15957 [==============================] - 5s 329us/step - loss: 39.6749 - root_mean_squared_error: 6.2158 - val_loss: 28.6270 - val_root_mean_squared_error: 5.2738\n",
            "Epoch 234/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 38.6680 - root_mean_squared_error: 6.1245 - val_loss: 28.2505 - val_root_mean_squared_error: 5.2496\n",
            "Epoch 235/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 36.9831 - root_mean_squared_error: 5.9914 - val_loss: 28.2790 - val_root_mean_squared_error: 5.2257\n",
            "Epoch 236/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 39.2168 - root_mean_squared_error: 6.1687 - val_loss: 27.2013 - val_root_mean_squared_error: 5.1142\n",
            "Epoch 237/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 37.7385 - root_mean_squared_error: 6.0477 - val_loss: 33.3850 - val_root_mean_squared_error: 5.6681\n",
            "Epoch 238/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 37.9331 - root_mean_squared_error: 6.0696 - val_loss: 26.6145 - val_root_mean_squared_error: 5.0732\n",
            "Epoch 239/250\n",
            "15957/15957 [==============================] - 5s 333us/step - loss: 39.2756 - root_mean_squared_error: 6.1669 - val_loss: 27.7290 - val_root_mean_squared_error: 5.1756\n",
            "Epoch 240/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 37.2598 - root_mean_squared_error: 6.0065 - val_loss: 35.1881 - val_root_mean_squared_error: 5.8241\n",
            "Epoch 241/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 37.4549 - root_mean_squared_error: 6.0308 - val_loss: 27.1818 - val_root_mean_squared_error: 5.1168\n",
            "Epoch 242/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 38.0963 - root_mean_squared_error: 6.0766 - val_loss: 28.6870 - val_root_mean_squared_error: 5.2726\n",
            "Epoch 243/250\n",
            "15957/15957 [==============================] - 5s 327us/step - loss: 38.0613 - root_mean_squared_error: 6.0777 - val_loss: 37.1872 - val_root_mean_squared_error: 5.9843\n",
            "Epoch 244/250\n",
            "15957/15957 [==============================] - 5s 328us/step - loss: 37.0208 - root_mean_squared_error: 5.9918 - val_loss: 27.9754 - val_root_mean_squared_error: 5.1996\n",
            "Epoch 245/250\n",
            "15957/15957 [==============================] - 5s 326us/step - loss: 37.1142 - root_mean_squared_error: 6.0097 - val_loss: 33.9974 - val_root_mean_squared_error: 5.7159\n",
            "Epoch 246/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 38.3106 - root_mean_squared_error: 6.1028 - val_loss: 32.8929 - val_root_mean_squared_error: 5.6376\n",
            "Epoch 247/250\n",
            "15957/15957 [==============================] - 5s 330us/step - loss: 38.3605 - root_mean_squared_error: 6.0830 - val_loss: 27.9192 - val_root_mean_squared_error: 5.2075\n",
            "Epoch 248/250\n",
            "15957/15957 [==============================] - 5s 331us/step - loss: 36.4391 - root_mean_squared_error: 5.9446 - val_loss: 30.0807 - val_root_mean_squared_error: 5.3883\n",
            "Epoch 249/250\n",
            "15957/15957 [==============================] - 5s 334us/step - loss: 37.6207 - root_mean_squared_error: 6.0342 - val_loss: 36.9894 - val_root_mean_squared_error: 5.9582\n",
            "Epoch 250/250\n",
            "15957/15957 [==============================] - 5s 332us/step - loss: 36.6687 - root_mean_squared_error: 5.9684 - val_loss: 27.9707 - val_root_mean_squared_error: 5.1869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H_S6LK541Gs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "4141ead6-0d27-4d91-cab3-a1f98b66934e"
      },
      "source": [
        "  cnnturbofan.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cnnturbofan\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 30, 14, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv0 (Conv2D)               (None, 30, 14, 10)        110       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 14, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 30, 14, 10)        1010      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 14, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 30, 14, 10)        1010      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 30, 14, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 30, 14, 10)        1010      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 30, 14, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 30, 14, 1)         31        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 30, 14, 1)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 420)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 420)               0         \n",
            "_________________________________________________________________\n",
            "fully-connected (Dense)      (None, 100)               42100     \n",
            "_________________________________________________________________\n",
            "rul-neuron (Dense)           (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 45,372\n",
            "Trainable params: 45,372\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj2BQVWTHspb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hola = cnnturbofan.predict(features_maps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOowaH-AMvuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "2b6613db-4e55-40bf-8445-c403face3336"
      },
      "source": [
        "#acc = history.history['mean_absolute_error']\n",
        "#val_acc = history.history['val_mean_absolute_error']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "##plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "#plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "#plt.title('Training and validation accuracy')\n",
        "#plt.legend()\n",
        "#plt.figure()\n",
        "\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.grid(True) \n",
        "plt.plot(epochs, loss, 'black',lw=0.9, label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'orange',lw=0.9, label='Validation Loss')\n",
        "plt.plot(epochs, np.ones(len(epochs))*12.2, 'blue',lw=1.3,label='Threshold')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "  \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAACxQAAAF1CAYAAADLd00CAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAAAAANhh/x9yJ3y0o8gv5QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 3600x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUeuUh9j8ygy",
        "colab_type": "text"
      },
      "source": [
        "## Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BE8_erqCr02P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_t = pd.read_csv('test_FD001.txt', sep = ' ', header = None)\n",
        "df_t = df_t.drop(columns=[26, 27])\n",
        "df_t.columns = ([\"n_engine\",\"cycle\",\"opset_1\",\"opset_2\",\"opset_3\",\n",
        "              \"sens_1\",\"sens_2\",\"sens_3\",\"sens_4\",\"sens_5\",\"sens_6\",\"sens_7\",\"sens_8\",\"sens_9\",\"sens_10\",\n",
        "              \"sens_11\",\"sens_12\",\"sens_13\",\"sens_14\",\"sens_15\",\"sens_16\",\"sens_17\",\"sens_18\",\"sens_19\",\"sens_20\",\"sens_21\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3xS5lNOkmts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "53909653-93e4-40d7-84b1-dfb9475e461a"
      },
      "source": [
        "df_t = df_t.drop(['sens_1','sens_5','sens_6','sens_10','sens_16','sens_18','sens_19'],axis=1)\n",
        "df_t"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_engine</th>\n",
              "      <th>cycle</th>\n",
              "      <th>opset_1</th>\n",
              "      <th>opset_2</th>\n",
              "      <th>opset_3</th>\n",
              "      <th>sens_2</th>\n",
              "      <th>sens_3</th>\n",
              "      <th>sens_4</th>\n",
              "      <th>sens_7</th>\n",
              "      <th>sens_8</th>\n",
              "      <th>sens_9</th>\n",
              "      <th>sens_11</th>\n",
              "      <th>sens_12</th>\n",
              "      <th>sens_13</th>\n",
              "      <th>sens_14</th>\n",
              "      <th>sens_15</th>\n",
              "      <th>sens_17</th>\n",
              "      <th>sens_20</th>\n",
              "      <th>sens_21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0023</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>643.02</td>\n",
              "      <td>1585.29</td>\n",
              "      <td>1398.21</td>\n",
              "      <td>553.90</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>9050.17</td>\n",
              "      <td>47.20</td>\n",
              "      <td>521.72</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8125.55</td>\n",
              "      <td>8.4052</td>\n",
              "      <td>392</td>\n",
              "      <td>38.86</td>\n",
              "      <td>23.3735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>-0.0027</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>641.71</td>\n",
              "      <td>1588.45</td>\n",
              "      <td>1395.42</td>\n",
              "      <td>554.85</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>9054.42</td>\n",
              "      <td>47.50</td>\n",
              "      <td>522.16</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>8139.62</td>\n",
              "      <td>8.3803</td>\n",
              "      <td>393</td>\n",
              "      <td>39.02</td>\n",
              "      <td>23.3916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.46</td>\n",
              "      <td>1586.94</td>\n",
              "      <td>1401.34</td>\n",
              "      <td>554.11</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>9056.96</td>\n",
              "      <td>47.50</td>\n",
              "      <td>521.97</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8130.10</td>\n",
              "      <td>8.4441</td>\n",
              "      <td>393</td>\n",
              "      <td>39.08</td>\n",
              "      <td>23.4166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.44</td>\n",
              "      <td>1584.12</td>\n",
              "      <td>1406.42</td>\n",
              "      <td>554.07</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>9045.29</td>\n",
              "      <td>47.28</td>\n",
              "      <td>521.38</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>8132.90</td>\n",
              "      <td>8.3917</td>\n",
              "      <td>391</td>\n",
              "      <td>39.00</td>\n",
              "      <td>23.3737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.51</td>\n",
              "      <td>1587.19</td>\n",
              "      <td>1401.92</td>\n",
              "      <td>554.16</td>\n",
              "      <td>2388.01</td>\n",
              "      <td>9044.55</td>\n",
              "      <td>47.31</td>\n",
              "      <td>522.15</td>\n",
              "      <td>2388.03</td>\n",
              "      <td>8129.54</td>\n",
              "      <td>8.4031</td>\n",
              "      <td>390</td>\n",
              "      <td>38.99</td>\n",
              "      <td>23.4130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13091</th>\n",
              "      <td>100</td>\n",
              "      <td>194</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>100.0</td>\n",
              "      <td>643.24</td>\n",
              "      <td>1599.45</td>\n",
              "      <td>1415.79</td>\n",
              "      <td>553.41</td>\n",
              "      <td>2388.02</td>\n",
              "      <td>9142.37</td>\n",
              "      <td>47.69</td>\n",
              "      <td>520.69</td>\n",
              "      <td>2388.00</td>\n",
              "      <td>8213.28</td>\n",
              "      <td>8.4715</td>\n",
              "      <td>394</td>\n",
              "      <td>38.65</td>\n",
              "      <td>23.1974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13092</th>\n",
              "      <td>100</td>\n",
              "      <td>195</td>\n",
              "      <td>-0.0011</td>\n",
              "      <td>-0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>643.22</td>\n",
              "      <td>1595.69</td>\n",
              "      <td>1422.05</td>\n",
              "      <td>553.22</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>9140.68</td>\n",
              "      <td>47.60</td>\n",
              "      <td>521.05</td>\n",
              "      <td>2388.09</td>\n",
              "      <td>8210.85</td>\n",
              "      <td>8.4512</td>\n",
              "      <td>395</td>\n",
              "      <td>38.57</td>\n",
              "      <td>23.2771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13093</th>\n",
              "      <td>100</td>\n",
              "      <td>196</td>\n",
              "      <td>-0.0006</td>\n",
              "      <td>-0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>643.44</td>\n",
              "      <td>1593.15</td>\n",
              "      <td>1406.82</td>\n",
              "      <td>553.04</td>\n",
              "      <td>2388.11</td>\n",
              "      <td>9146.81</td>\n",
              "      <td>47.57</td>\n",
              "      <td>521.18</td>\n",
              "      <td>2388.04</td>\n",
              "      <td>8217.24</td>\n",
              "      <td>8.4569</td>\n",
              "      <td>395</td>\n",
              "      <td>38.62</td>\n",
              "      <td>23.2051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13094</th>\n",
              "      <td>100</td>\n",
              "      <td>197</td>\n",
              "      <td>-0.0038</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>100.0</td>\n",
              "      <td>643.26</td>\n",
              "      <td>1594.99</td>\n",
              "      <td>1419.36</td>\n",
              "      <td>553.37</td>\n",
              "      <td>2388.07</td>\n",
              "      <td>9148.85</td>\n",
              "      <td>47.61</td>\n",
              "      <td>521.33</td>\n",
              "      <td>2388.08</td>\n",
              "      <td>8220.48</td>\n",
              "      <td>8.4711</td>\n",
              "      <td>395</td>\n",
              "      <td>38.66</td>\n",
              "      <td>23.2699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13095</th>\n",
              "      <td>100</td>\n",
              "      <td>198</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0003</td>\n",
              "      <td>100.0</td>\n",
              "      <td>642.95</td>\n",
              "      <td>1601.62</td>\n",
              "      <td>1424.99</td>\n",
              "      <td>552.48</td>\n",
              "      <td>2388.06</td>\n",
              "      <td>9155.03</td>\n",
              "      <td>47.80</td>\n",
              "      <td>521.07</td>\n",
              "      <td>2388.05</td>\n",
              "      <td>8214.64</td>\n",
              "      <td>8.4903</td>\n",
              "      <td>396</td>\n",
              "      <td>38.70</td>\n",
              "      <td>23.1855</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13096 rows  19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       n_engine  cycle  opset_1  opset_2  ...  sens_15  sens_17  sens_20  sens_21\n",
              "0             1      1   0.0023   0.0003  ...   8.4052      392    38.86  23.3735\n",
              "1             1      2  -0.0027  -0.0003  ...   8.3803      393    39.02  23.3916\n",
              "2             1      3   0.0003   0.0001  ...   8.4441      393    39.08  23.4166\n",
              "3             1      4   0.0042   0.0000  ...   8.3917      391    39.00  23.3737\n",
              "4             1      5   0.0014   0.0000  ...   8.4031      390    38.99  23.4130\n",
              "...         ...    ...      ...      ...  ...      ...      ...      ...      ...\n",
              "13091       100    194   0.0049   0.0000  ...   8.4715      394    38.65  23.1974\n",
              "13092       100    195  -0.0011  -0.0001  ...   8.4512      395    38.57  23.2771\n",
              "13093       100    196  -0.0006  -0.0003  ...   8.4569      395    38.62  23.2051\n",
              "13094       100    197  -0.0038   0.0001  ...   8.4711      395    38.66  23.2699\n",
              "13095       100    198   0.0013   0.0003  ...   8.4903      396    38.70  23.1855\n",
              "\n",
              "[13096 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEMbnv78Pzxi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b4b7ef87-85d6-4ca5-878a-848bebdf5a25"
      },
      "source": [
        "ruls_test= []\n",
        "rul_file = open(\"RUL_FD001.txt\", \"r\")\n",
        "for rul_line in rul_file:\n",
        "  ruls_test.append(int(rul_line.rstrip(' \\n')))\n",
        "print(ruls_test)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[112, 98, 69, 82, 91, 93, 91, 95, 111, 96, 97, 124, 95, 107, 83, 84, 50, 28, 87, 16, 57, 111, 113, 20, 145, 119, 66, 97, 90, 115, 8, 48, 106, 7, 11, 19, 21, 50, 142, 28, 18, 10, 59, 109, 114, 47, 135, 92, 21, 79, 114, 29, 26, 97, 137, 15, 103, 37, 114, 100, 21, 54, 72, 28, 128, 14, 77, 8, 121, 94, 118, 50, 131, 126, 113, 10, 34, 107, 63, 90, 8, 9, 137, 58, 118, 89, 116, 115, 136, 28, 38, 20, 85, 55, 128, 137, 82, 59, 117, 20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQuHp05L9Dki",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "6800357c-155b-4431-edae-1de1b72e2afc"
      },
      "source": [
        "df_t[df_t.columns[1:19]]= scaler.transform(df_t[df_t.columns[1:19]])\n",
        "df_t"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>n_engine</th>\n",
              "      <th>cycle</th>\n",
              "      <th>opset_1</th>\n",
              "      <th>opset_2</th>\n",
              "      <th>opset_3</th>\n",
              "      <th>sens_2</th>\n",
              "      <th>sens_3</th>\n",
              "      <th>sens_4</th>\n",
              "      <th>sens_7</th>\n",
              "      <th>sens_8</th>\n",
              "      <th>sens_9</th>\n",
              "      <th>sens_11</th>\n",
              "      <th>sens_12</th>\n",
              "      <th>sens_13</th>\n",
              "      <th>sens_14</th>\n",
              "      <th>sens_15</th>\n",
              "      <th>sens_17</th>\n",
              "      <th>sens_20</th>\n",
              "      <th>sens_21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.264368</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.090361</td>\n",
              "      <td>-0.378679</td>\n",
              "      <td>-0.461175</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>-0.575758</td>\n",
              "      <td>-0.744773</td>\n",
              "      <td>-0.583333</td>\n",
              "      <td>0.292111</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.735680</td>\n",
              "      <td>-0.382070</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.323667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.994460</td>\n",
              "      <td>-0.310345</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.698795</td>\n",
              "      <td>-0.240898</td>\n",
              "      <td>-0.555368</td>\n",
              "      <td>0.610306</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.706632</td>\n",
              "      <td>-0.226190</td>\n",
              "      <td>0.479744</td>\n",
              "      <td>-0.470588</td>\n",
              "      <td>-0.590463</td>\n",
              "      <td>-0.573682</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.364341</td>\n",
              "      <td>0.373654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.988920</td>\n",
              "      <td>0.034483</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.246988</td>\n",
              "      <td>-0.306736</td>\n",
              "      <td>-0.355503</td>\n",
              "      <td>0.371981</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>-0.683837</td>\n",
              "      <td>-0.226190</td>\n",
              "      <td>0.398721</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.688719</td>\n",
              "      <td>-0.082724</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.457364</td>\n",
              "      <td>0.442695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.983380</td>\n",
              "      <td>0.482759</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.259036</td>\n",
              "      <td>-0.429693</td>\n",
              "      <td>-0.183997</td>\n",
              "      <td>0.359098</td>\n",
              "      <td>-0.606061</td>\n",
              "      <td>-0.788567</td>\n",
              "      <td>-0.488095</td>\n",
              "      <td>0.147122</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.659820</td>\n",
              "      <td>-0.485956</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.324220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.977839</td>\n",
              "      <td>0.160920</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>-0.216867</td>\n",
              "      <td>-0.295836</td>\n",
              "      <td>-0.335922</td>\n",
              "      <td>0.388084</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>-0.795208</td>\n",
              "      <td>-0.452381</td>\n",
              "      <td>0.475480</td>\n",
              "      <td>-0.558824</td>\n",
              "      <td>-0.694499</td>\n",
              "      <td>-0.398230</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>0.317829</td>\n",
              "      <td>0.432753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13091</th>\n",
              "      <td>100</td>\n",
              "      <td>0.069252</td>\n",
              "      <td>0.563218</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.222892</td>\n",
              "      <td>0.238718</td>\n",
              "      <td>0.132343</td>\n",
              "      <td>0.146538</td>\n",
              "      <td>-0.636364</td>\n",
              "      <td>0.082653</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.147122</td>\n",
              "      <td>-0.647059</td>\n",
              "      <td>0.169780</td>\n",
              "      <td>0.128126</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.209302</td>\n",
              "      <td>-0.162662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13092</th>\n",
              "      <td>100</td>\n",
              "      <td>0.074792</td>\n",
              "      <td>-0.126437</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.210843</td>\n",
              "      <td>0.074777</td>\n",
              "      <td>0.343687</td>\n",
              "      <td>0.085346</td>\n",
              "      <td>-0.545455</td>\n",
              "      <td>0.067486</td>\n",
              "      <td>-0.107143</td>\n",
              "      <td>0.006397</td>\n",
              "      <td>-0.382353</td>\n",
              "      <td>0.144700</td>\n",
              "      <td>-0.028088</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>0.057443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13093</th>\n",
              "      <td>100</td>\n",
              "      <td>0.080332</td>\n",
              "      <td>-0.068966</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.343373</td>\n",
              "      <td>-0.035971</td>\n",
              "      <td>-0.170493</td>\n",
              "      <td>0.027375</td>\n",
              "      <td>-0.363636</td>\n",
              "      <td>0.122498</td>\n",
              "      <td>-0.142857</td>\n",
              "      <td>0.061834</td>\n",
              "      <td>-0.529412</td>\n",
              "      <td>0.210651</td>\n",
              "      <td>0.015775</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.255814</td>\n",
              "      <td>-0.141397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13094</th>\n",
              "      <td>100</td>\n",
              "      <td>0.085873</td>\n",
              "      <td>-0.436782</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.234940</td>\n",
              "      <td>0.044256</td>\n",
              "      <td>0.252870</td>\n",
              "      <td>0.133655</td>\n",
              "      <td>-0.484848</td>\n",
              "      <td>0.140806</td>\n",
              "      <td>-0.095238</td>\n",
              "      <td>0.125800</td>\n",
              "      <td>-0.411765</td>\n",
              "      <td>0.244091</td>\n",
              "      <td>0.125048</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.193798</td>\n",
              "      <td>0.037559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13095</th>\n",
              "      <td>100</td>\n",
              "      <td>0.091413</td>\n",
              "      <td>0.149425</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0.048193</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.442944</td>\n",
              "      <td>-0.152979</td>\n",
              "      <td>-0.515152</td>\n",
              "      <td>0.196267</td>\n",
              "      <td>0.130952</td>\n",
              "      <td>0.014925</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.183817</td>\n",
              "      <td>0.272797</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>-0.131783</td>\n",
              "      <td>-0.195526</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13096 rows  19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       n_engine     cycle   opset_1  ...   sens_17   sens_20   sens_21\n",
              "0             1 -1.000000  0.264368  ... -0.333333  0.116279  0.323667\n",
              "1             1 -0.994460 -0.310345  ... -0.166667  0.364341  0.373654\n",
              "2             1 -0.988920  0.034483  ... -0.166667  0.457364  0.442695\n",
              "3             1 -0.983380  0.482759  ... -0.500000  0.333333  0.324220\n",
              "4             1 -0.977839  0.160920  ... -0.666667  0.317829  0.432753\n",
              "...         ...       ...       ...  ...       ...       ...       ...\n",
              "13091       100  0.069252  0.563218  ...  0.000000 -0.209302 -0.162662\n",
              "13092       100  0.074792 -0.126437  ...  0.166667 -0.333333  0.057443\n",
              "13093       100  0.080332 -0.068966  ...  0.166667 -0.255814 -0.141397\n",
              "13094       100  0.085873 -0.436782  ...  0.166667 -0.193798  0.037559\n",
              "13095       100  0.091413  0.149425  ...  0.333333 -0.131783 -0.195526\n",
              "\n",
              "[13096 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpNkOxXpH6oS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_maps_test=np.empty((30,14,1))\n",
        "for i in range(1,df_t['n_engine'].max()+1):\n",
        "  #se obtienen los dataset de engines independientes en df_temp\n",
        "  df_temp = df_t[df_t['n_engine'] == i].drop(['n_engine','cycle','opset_1','opset_2','opset_3'],axis=1)\n",
        "  df_large = df_temp['sens_8'].count()\n",
        "  feature_map = df_temp[df_large-30:][:]\n",
        "  features_maps_test = np.dstack((features_maps_test, feature_map))\n",
        "features_maps_test=np.delete(features_maps_test, 0, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGTMJgX5XBo9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "55f6b98b-94ae-4f7f-8ead-9c65093be613"
      },
      "source": [
        "print(features_maps_test.shape)\n",
        "print(feature_map.shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 14, 100)\n",
            "(30, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I3J3SksZo7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9af781ac-f235-4c1a-da1c-7f38d845f9ed"
      },
      "source": [
        "features_maps_test = np.moveaxis(features_maps_test, 2, 0)\n",
        "print(features_maps_test.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 30, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezAIjNxodVmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f46af9d8-b94f-4a66-fe14-f1a7971395e3"
      },
      "source": [
        "features_maps_test= np.expand_dims(features_maps_test,3)\n",
        "print(features_maps_test.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 30, 14, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEIWASmadiAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list1 = np.array(ruls_test)\n",
        "list2 = np.array(features_maps_test)\n",
        "idx   = np.argsort(list1)\n",
        "\n",
        "list1 = np.array(list1)[idx]\n",
        "list2 = np.array(list2)[idx]\n",
        "\n",
        "for i in range(len(list1)):\n",
        "  if list1[i] >= 125:\n",
        "    list1[i] = 125\n",
        "  else:\n",
        "    list1[i] = list1[i]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rAzJ5XOfu4C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "f6f378e8-4bc8-4784-8918-a41c88eccf47"
      },
      "source": [
        "print(list1)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  7   8   8   8   9  10  10  11  14  15  16  18  19  20  20  20  21  21\n",
            "  21  26  28  28  28  28  29  34  37  38  47  48  50  50  50  54  55  57\n",
            "  58  59  59  63  66  69  72  77  79  82  82  83  84  85  87  89  90  90\n",
            "  91  91  92  93  94  95  95  96  97  97  97  98 100 103 106 107 107 109\n",
            " 111 111 112 113 113 114 114 114 115 115 116 117 118 118 119 121 124 125\n",
            " 125 125 125 125 125 125 125 125 125 125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5CSaPRxgIdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "holi = cnnturbofan.predict(list2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6cxUshdgvAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "f7fefece-dfbf-4244-875e-8e5ef417c318"
      },
      "source": [
        "leng = range(100)\n",
        "\n",
        "#plt.plot(leng, acc, 'r', label='Training accuracy')\n",
        "#plt.plot(leng, val_acc, 'b', label='Validation accuracy')\n",
        "#plt.title('Training and validation accuracy')\n",
        "#plt.legend()\n",
        "#plt.figure()\n",
        "\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.grid(True) \n",
        "plt.plot(leng, holi, 'bo',lw=0.9, label='predict')\n",
        "plt.plot(leng, list1, 'ro',lw=0.9, label='true')\n",
        "plt.title('True and predict')\n",
        "plt.legend()\n",
        "  \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAE/CAYAAAAwpsSrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4mcYRlPy/wG/eZpNf59IRwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6087uYvh0jm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3230e1b-b932-46ad-f38d-baa180960e74"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse = sqrt(mean_squared_error(holi, list1))\n",
        "print(rmse)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.385772970806748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIcT4aXFmFn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}